{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 4o: Neural Networks on Sequential Data\n",
    "\n",
    "**Release Date:** 28 October\n",
    "\n",
    "**Due Date:** 2 November"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "We will learn the details of RNN/LSTM, as well as their applications to sequential data. In the first task, we will use an RNN to model and predict patterns in time-series data, specifically using sine wave. The second task focuses on a text classification, where we will employ LSTM network to classify reviews from movie reviews dataset as positive or negative.\n",
    "\n",
    "**Required Files**:\n",
    "* ps4o.ipynb\n",
    "* data/\n",
    "    * review_train.csv\n",
    "    * review_test.csv\n",
    "\n",
    "**Plagiarism Policy**: Please refer to our [Course Policies](https://canvas.nus.edu.sg/courses/62323/pages/course-policies).\n",
    "\n",
    "**IMPORTANT**: While it is possible to write and run Python code directly in Jupyter notebook, we recommend that you do this Problem set with an IDE using the .py file provided. An IDE will make debugging significantly easier.\n",
    "\n",
    "**Post-Problem Set Survey**:\n",
    "Your feedback is important to us! After completing Problem Set 4o, please take a moment to share your thoughts by filling out this [survey](https://coursemology.org/courses/2851/surveys/2457)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT\n",
    "\n",
    "Your implementation in the following tasks **should not\n",
    "involve any iteration, including `map` and `filter`, or recursion**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "The necessary packages are imported in the cell below. Please make sure that you run this cell before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.12.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(2109)\n",
    "np.random.seed(2109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple RNN to Learn Sine Wave\n",
    "\n",
    "In this task, you will create a simple RNN model to predict values of a sine wave based on prior inputs. The goal is for the RNN to learn the underlying pattern of the sine wave and use this understanding to predict unseen values in the sequence.\n",
    "\n",
    "Through this exercies, you'll develop an understanding of how RNNs handle dependencies over time and how they can be trained to make predictions on continuous data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: RNN Cell\n",
    "\n",
    "<center><img src=\"images/rnn.png\" style=\"width:500px;height:300px\"></center>\n",
    "\n",
    "At the core of the RNN is the RNN cell, which processes one time step of the sequence at a time. For each time step, the cell updates its hidden state based on the current input and the previous hidden state.\n",
    "\n",
    "We first implement the computations for a single time step. The diagram below describes the operations for a single time step of an RNN cell.\n",
    "<center><img src=\"images/rnn_cell.png\" style=\"width:700px;height:300px;\"></center>\n",
    "\n",
    "__Note__: an RNN cell outputs the hidden state $h_t$, but the function that you'll implement `rnn_cell_forward`, also calculates the prediction $\\hat{y}_t$. Keep in mind that the activation functions within the RNN cell can be replaced with other activation functions. For this task, tanh and softmax are used, but they can be replaced by other activation functions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_cell_forward(xt, h_prev, Wxh, Whh, Why, bh, by):\n",
    "    \"\"\"\n",
    "    Implements a single forward step of the RNN-cell\n",
    "\n",
    "    Args:\n",
    "        xt: 2D tensor of shape (nx, m)\n",
    "            Input data at timestep \"t\"\n",
    "        h_prev: 2D tensor of shape (nh, m)\n",
    "            Hidden state at timestep \"t-1\"\n",
    "        Wxh: 2D tensor of shape (nx, nh)\n",
    "            Weight matrix multiplying the input\n",
    "        Whh: 2D tensor of shape (nh, nh)\n",
    "            Weight matrix multiplying the hidden state\n",
    "        Why: 2D tensor of shape (nh, ny)\n",
    "            Weight matrix relating the hidden-state to the output\n",
    "        bh: 1D tensor of shape (nh, 1)\n",
    "            Bias relating to next hidden-state\n",
    "        by: 2D tensor of shape (ny, 1)\n",
    "            Bias relating the hidden-state to the output\n",
    "\n",
    "    Returns:\n",
    "        yt_pred -- prediction at timestep \"t\", tensor of shape (ny, m)\n",
    "        h_next -- next hidden state, of shape (nh, m)\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    h_next = torch.tanh(Wxh.T @ xt + Whh.T @ h_prev + bh)\n",
    "    yt_pred = torch.softmax(Why.T @ h_next + by, dim=0)\n",
    "    print(yt_pred)\n",
    "    return yt_pred, h_next\n",
    "    \"\"\" YOUR CODE END HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7311, 0.7311, 0.7311],\n",
      "        [0.2689, 0.2689, 0.2689]])\n"
     ]
    }
   ],
   "source": [
    "# Test cases\n",
    "public_paras = {\n",
    "    'xt': torch.tensor([[1., 1., 2.], [2., 1., 3.], [3., 5., 3.]]),\n",
    "    'h_prev': torch.tensor([[5., 3., 2.], [1., 3., 2.]]),\n",
    "    'Wxh': torch.tensor([[2., 2.], [3., 4.], [4., 3.]]),\n",
    "    'Whh': torch.tensor([[2., 4.], [2., 3.]]),\n",
    "    'Why': torch.tensor([[3., 5.], [5., 4.]]),\n",
    "    'bh': torch.tensor([[1.], [2.]]),\n",
    "    'by': torch.tensor([[3.], [1.]]),\n",
    "}\n",
    "\n",
    "expected_yt_pred = torch.tensor([[0.7311, 0.7311, 0.7311], [0.2689, 0.2689, 0.2689]])\n",
    "expected_h_next = torch.tensor([[1., 1., 1.], [1., 1., 1.]])\n",
    "\n",
    "actual_yt_pred, actual_h_next = rnn_cell_forward(**public_paras)\n",
    "assert torch.allclose(actual_yt_pred, expected_yt_pred, atol=1e-4)\n",
    "assert torch.allclose(actual_h_next, expected_h_next, atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: Generate Sine Wave Data\n",
    "\n",
    "Use torch.linspace(start, end, steps) to create a sequence of evenly spaced values between 0 and $8\\pi$ over `num_time_steps` intervals. This will serve as the x-values (time points) for the sine wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sine_wave(num_time_steps):\n",
    "    \"\"\"\n",
    "    Generates a sine wave data\n",
    "\n",
    "    Args:\n",
    "        num_time_steps: int\n",
    "            Number of time steps\n",
    "    Returns:\n",
    "        data: 1D tensor of shape (num_time_steps,)\n",
    "            Sine wave data with corresponding time steps\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    return torch.linspace(0, 8*np.pi, num_time_steps).sin()\n",
    "    \"\"\" YOUR CODE END HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "num_time_steps_public = 5\n",
    "expected_data_public = torch.tensor([0.0000e+00, 1.7485e-07, 3.4969e-07, 4.7700e-08, 6.9938e-07])\n",
    "actual_data = generate_sine_wave(num_time_steps_public)\n",
    "\n",
    "assert torch.allclose(actual_data, expected_data_public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_time_steps = 500\n",
    "sine_wave_data = generate_sine_wave(num_time_steps)\n",
    "\n",
    "# Plot the sine wave\n",
    "plt.plot(sine_wave_data)\n",
    "plt.title('Sine Wave')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3: Create sequences\n",
    "\n",
    "When training RNN, it's common to divide time series data into overlapping windows. The label used for comparison is the next value in the sequence.\n",
    "\n",
    "For example if we have series of $n$ data points and a window size of 3, the input sequences are $[x_1, x_2, x_3]$ to predict $x_4$, $[x_2, x_3, x_4]$ to predict $x_5$, $[x_3, x_4, x_5]$, to predict $x_6$, and so on.\n",
    "\n",
    "You will implement function `create_sequences` which generates sequences and their corresponding labels from a given sine wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(sine_wave, seq_length):\n",
    "    \"\"\"\n",
    "    Create overlapping sequences from the input time series and generate labels \n",
    "    Each label is the value immediately following the corresponding sequence.\n",
    "    \n",
    "    Args:\n",
    "        sine_wave: A 1D tensor representing the time series data (e.g., sine wave).\n",
    "        seq_length: int. The length of each sequence (window) to be used as input to the RNN.\n",
    "\n",
    "    Returns: \n",
    "        windows: 2D tensor where each row is a sequence (window) of length `seq_length`.\n",
    "        labels: 1D tensor where each element is the next value following each window.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    windows = sine_wave.unfold(0, seq_length, 1)[:-1]\n",
    "    labels = sine_wave[seq_length:]\n",
    "    return windows, labels\n",
    "    \"\"\" YOUR CODE END HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "seq_length_test = 2\n",
    "sine_wave_test = torch.tensor([0., 1., 2., 3.])\n",
    "expected_sequences = torch.tensor([[0., 1.], [1., 2.]])\n",
    "expected_labels = torch.tensor([2., 3.])\n",
    "\n",
    "actual_sequences, actual_labels = create_sequences(sine_wave_test, seq_length_test)\n",
    "assert torch.allclose(actual_sequences, expected_sequences)\n",
    "assert torch.allclose(actual_labels, expected_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sequences: torch.Size([480, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([480, 20, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sequences and labels\n",
    "seq_length = 20\n",
    "sequences, labels = create_sequences(sine_wave_data, seq_length)\n",
    "print(f\"Shape of sequences: {sequences.shape}\")\n",
    "# Add extra dimension to match RNN input shape [batch_size, seq_length, num_features]\n",
    "sequences = sequences.unsqueeze(-1)\n",
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the sequences into training data (first 80%) and test data (remaining 20%) \n",
    "train_size = int(len(sequences) * 0.8)\n",
    "train_seqs, train_labels = sequences[:train_size], labels[:train_size]\n",
    "\n",
    "\n",
    "\n",
    "test_seqs, test_labels = sequences[train_size:], labels[train_size:]\n",
    "train_labels.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.4: Building RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Architecture\n",
    "$$x \\rightarrow \\text{RNN} \\rightarrow \\text{Linear}(1)$$\n",
    "\n",
    "- [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html): a basic recurrent layer in PyTorch. It takes an input of sequences and returns output for each time step, and the hidden state of the last time step. The `hidden_size` determines the number of hidden units in the RNN.\n",
    " \n",
    "- [Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html): fully connected layer. The output from the RNN's last hidden state will be passed through this layer to predict a single value (the next time step in the series)\n",
    "\n",
    "__Note:__ For all your networks hereon, the only constructor argument is `classes`. Do not add any other parameters to the `__init__` method. Remember not to hardcode and use the `classes` argument instead. For RNN layer, use `batch_first=True` to ensure that the batch dimension is handled as the first input dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        Initialize the SineRNN model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): The number of input features per time step (typically 1 for univariate time series).\n",
    "            hidden_size (int): The number of units in the RNN's hidden layer.\n",
    "            output_size (int): The size of the output (usually 1 for predicting a single value).\n",
    "        \"\"\"\n",
    "        super(SineRNN, self).__init__()\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \"\"\" YOUR CODE END HERE \"\"\"\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        output, _ = self.rnn(x) #dunnid ht since only 1 rnn layer\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "        \"\"\" YOUR CODE END HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "input_size = output_size = 1\n",
    "hidden_size = 50\n",
    "model = SineRNN(input_size, hidden_size, output_size)\n",
    "assert [layer.detach().numpy().shape for _, layer in model.named_parameters()]\\\n",
    "      == [(50, 1), (50, 50), (50,), (50,), (1, 50), (1,)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function, and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200], Loss: 0.508875\n",
      "Epoch [40/200], Loss: 0.508875\n",
      "Epoch [60/200], Loss: 0.508875\n",
      "Epoch [80/200], Loss: 0.508875\n",
      "Epoch [100/200], Loss: 0.508875\n",
      "Epoch [120/200], Loss: 0.508875\n",
      "Epoch [140/200], Loss: 0.508875\n",
      "Epoch [160/200], Loss: 0.508875\n",
      "Epoch [180/200], Loss: 0.508875\n",
      "Epoch [200/200], Loss: 0.508875\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(train_seqs)\n",
    "    loss = criterion(outputs.squeeze(1), train_labels)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating\n",
    "\n",
    "Once training is complete, we can evaluate the model by plotting its predictions against the actual sine wave. We use a portion of test data that the model hasn't seen during training to check how well it generalizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on unseen data\n",
    "model.eval()\n",
    "y_pred = []\n",
    "input_seq = test_seqs[0]  # Start with the first testing sequence\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(len(test_seqs)):\n",
    "        output = model(input_seq)\n",
    "        y_pred.append(output.detach().numpy()) \n",
    "\n",
    "        # Use the predicted value as the next input sequence\n",
    "        next_seq = torch.cat((input_seq[1:, :], output.squeeze(0)), dim=0)\n",
    "        input_seq = next_seq\n",
    "\n",
    "# Plot the true sine wave and predictions\n",
    "plt.plot(sine_wave_data, c='gray', label='Actual data')\n",
    "plt.scatter(np.arange(seq_length + len(train_labels)), sine_wave_data[:seq_length + len(train_labels)], marker='.', label='Train')\n",
    "x_axis_pred = np.arange(len(sine_wave_data) - len(test_labels), len(sine_wave_data))\n",
    "plt.scatter(x_axis_pred, y_pred, marker='.', label='Predicted')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LSTM for Text Classification\n",
    "\n",
    "Text classification in Natural Language Processing (NLP) involves automatically assigning predefined labels to textual data based on its content. It is a fundamental problem in NLP with a wide range of applications, including sentiment analysis, spam detection, and topic labeling, etc. The goal of text classification is to train a model that can learn patterns and features from labeled training data and use that knowledge to classify new, unseen text into predefined categories. These categories can be binary (e.g., positive/negative sentiment) or multiclass (e.g., sports, politics, entertainment).\n",
    "\n",
    "In this task, we will train an LSTM-based sentiment classifier using IMDb movie reviews dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: LSTM Cell\n",
    "\n",
    "The following figure shows the operations of an LSTM cell (Adopted from [Soure](https://d2l.ai/chapter_recurrent-modern/lstm.html#fig-lstm-3)).\n",
    "\n",
    "<center><img src=\"images/lstm_cell.png\" style=\"width:400;height:300px\"></center>\n",
    "\n",
    "where $\\sigma$ is the sigmoid function and $\\odot$ is the Hadamard product. \n",
    "\n",
    "Let $[\\mathbf{H}_{t - 1}, \\mathbf{X}_t\\bigl]$ be the concatenation of hidden state $\\mathbf{H}_{t - 1}$ and current time step's input $\\mathbf{X}_t$, we have the equations for the forward pass of an LSTM cell as follows:\n",
    "\n",
    "- **Forget Gate $\\mathbf{F}_t$**: responsible for deciding which information is kept for calculating the cell state and which is not relevant and can be discarded\n",
    "$$\\mathbf{F}_{t} = \\sigma\\Bigl(\\mathbf{W}_f\\bigl[\\mathbf{H}_{t - 1}, \\mathbf{X}_t\\bigl] + b_f\\Bigl)$$\n",
    "- **Input Gate $\\mathbf{I}_t$**: updates the cell state and decides which information is important and which is not. As forget gate helps to discard the information, the input gate helps to find out important information and store certain data in the memory that relevant\n",
    "$$\\mathbf{I}_{t} = \\sigma\\Bigl(\\mathbf{W}_i\\bigl[\\mathbf{H}_{t - 1}, \\mathbf{X}_t\\bigl] + b_i\\Bigl)$$\n",
    "- **Candidate $\\tilde{\\mathbf{C}}_t$**\n",
    "$$\\tilde{\\mathbf{C}}_{t} = \\tanh\\Bigl(\\mathbf{W}_c\\bigl[\\mathbf{H}_{t - 1}, \\mathbf{X}_t\\bigl] + b_c\\Bigl)$$\n",
    "- **Output Gate $\\mathbf{O}_t$**: decides what the next hidden state should be\n",
    "$$\\mathbf{O}_{t} = \\sigma\\Bigl(\\mathbf{W}_o\\bigl[\\mathbf{H}_{t - 1}, \\mathbf{X}_t\\bigl] + b_o\\Bigl)$$\n",
    "- **Memory Cell State $\\mathbf{C}_t$**\n",
    "$$\\mathbf{C}_{t} = \\mathbf{F}_t * \\mathbf{C}_{t-1} + \\mathbf{I}_t * \\tilde{\\mathbf{C}}_{t}$$\n",
    "- **Hidden State $\\mathbf{H}_t$**\n",
    "$$\\mathbf{H}_{t} = \\mathbf{O}_t * \\tanh\\bigl(\\mathbf{C}_{t}\\bigl)$$\n",
    "\n",
    "Similar to the RNN example, you'll begin by implementing the LSTM cell for a single time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell_forward(xt, h_prev, c_prev, Wf, bf, Wi, bi, Wc, bc, Wo, bo):\n",
    "    \"\"\"\n",
    "    Implement a single forward step of the LSTM cell\n",
    "\n",
    "    Args:\n",
    "        xt: 2D tensor of shape (nx, m)\n",
    "            Input data at timestep \"t\"\n",
    "        h_prev: 2D tensor of shape (nh, m)\n",
    "            Hidden state at timestep \"t-1\"\n",
    "        c_prev: 2D tensor of shape (nh, m)\n",
    "            Memory state at timestep \"t-1\"\n",
    "        Wf: tensor of shape(nh, nh + nx) \n",
    "            Weight matrix of the forget gate\n",
    "        bf: tensor of shape (nh, 1)\n",
    "            Bias of the forget gate\n",
    "        Wi: tensor of shape (nh, nh + nx)\n",
    "            Weight matrix of the input gate\n",
    "        bi: tensor of shape (nh, 1)\n",
    "            Bias of the input gate\n",
    "        Wc: tensor of shape (nh, nh + nx)\n",
    "            Weight matrix of candidate value\n",
    "        bc: tensor of shape (nh, 1)\n",
    "            Bias of the candidate value\n",
    "        Wo: tensor of shape (nh, nh + nx)\n",
    "            Weight matrix of the output gate\n",
    "        bo: tensor of shape (nh, 1) \n",
    "            Bias of the output gate\n",
    "    \n",
    "    Returns:\n",
    "        h_next: 2D tensor of shape (nh, m), next hidden state\n",
    "        c_next: 2D tensor of shape (nh, m), next memory state\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    concat = torch.cat((h_prev, xt), dim=0)\n",
    "    ft = torch.sigmoid(Wf @ concat + bf)\n",
    "    it = torch.sigmoid(Wi @ concat + bi)\n",
    "    ct = torch.tanh(Wc @ concat + bc)\n",
    "    c_next = ft * c_prev + it * ct\n",
    "    ot = torch.sigmoid(Wo @ concat + bo)\n",
    "    h_next = ot * torch.tanh(c_next)\n",
    "    return h_next, c_next\n",
    "    \"\"\" YOUR CODE END HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "public_paras = {\n",
    "    'xt': torch.tensor([[1.], [2.], [3.]]),\n",
    "    'h_prev': torch.tensor([[1.], [2.]]),\n",
    "    'c_prev': torch.tensor([[1.], [2.]]),\n",
    "    'Wf': torch.tensor([[1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.]]),\n",
    "    'bf': torch.tensor([[1.], [1.]]),\n",
    "    'Wi': torch.tensor([[1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.]]),\n",
    "    'bi': torch.tensor([[1.], [1.]]),\n",
    "    'Wc': torch.tensor([[1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.]]),\n",
    "    'bc': torch.tensor([[1.], [1.]]),\n",
    "    'Wo': torch.tensor([[1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.]]),\n",
    "    'bo': torch.tensor([[1.], [1.]])\n",
    "}\n",
    "expected_h_next = torch.tensor([[0.9640], [0.9950]])\n",
    "expected_c_next = torch.tensor([[1.9999], [2.9999]])\n",
    "\n",
    "actual_h_next, actual_c_next = lstm_cell_forward(**public_paras)\n",
    "assert torch.allclose(actual_h_next, expected_h_next, atol=1e-4)\n",
    "assert torch.allclose(actual_c_next, expected_c_next, atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence Polarity Dataset\n",
    "The [Sentence Polarity Dataset](https://www.kaggle.com/datasets/nltkdata/sentence-polarity) is a widely used dataset for sentiment analysis and text classification tasks. The reviews are sampled from Rotten Tomatoes webpages and labeled with sentiment polarity, indicating whether the review expresses a positive or negative sentiment towards the movie.\n",
    "\n",
    "In this task, we use a subset of the dataset consisting of 10,000 reviews, equally divided between 5,000 positive and 5,000 negative reviews. The dataset is pre-split into a training set with 8,000 reviews and a test set with 2,000 reviews. Each set maintains an even distribution of positive and negative reviews. The data is available at `data/` directory. The .csv files contain two columns: `review` and `label`, where 0 means the review is negative and 1 means the review is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a reminder that beyond all the hype and recent...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jaglom . . . put[s] the audience in the privil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if myers decides to make another austin powers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" bad \" is the operative word for \" bad compa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if you love the music , and i do , its hard to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>an awful lot like one of [spears'] music video...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bouquet gives a performance that is masterly .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>there are a few stabs at absurdist comedy . . ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>harland williams is so funny in drag he should...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>creepy , authentic and dark . this disturbing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  a reminder that beyond all the hype and recent...      1\n",
       "1  jaglom . . . put[s] the audience in the privil...      1\n",
       "2  if myers decides to make another austin powers...      0\n",
       "3   \" bad \" is the operative word for \" bad compa...      0\n",
       "4  if you love the music , and i do , its hard to...      1\n",
       "5  an awful lot like one of [spears'] music video...      0\n",
       "6    bouquet gives a performance that is masterly .       1\n",
       "7  there are a few stabs at absurdist comedy . . ...      1\n",
       "8  harland williams is so funny in drag he should...      0\n",
       "9  creepy , authentic and dark . this disturbing ...      1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from files\n",
    "train_df = pd.read_csv('data/review_train.csv')\n",
    "test_df = pd.read_csv('data/review_test.csv')\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    4000\n",
       "0    4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the training dataset has 4,000 positive reviews (label = 1) and 4,000 negative reviews (label = 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Dataset\n",
    "\n",
    "In the previous PS, we used available datasets in PyTorch (MNIST, CIFAR) to train the networks. However, in this task, we will need to prepare the data ourselves. Using Dataset offers several advantages, including cleaner code and support for parallel processing on multiple CPUs or GPUs. It also optimizes data transfer between the CPU and GPU, which is crucial when working with large datasets. It is therefore the recommended best practice. \n",
    "\n",
    "We first create a simple `CustomDataset` which extends PyTorch's `Dataset`. This class only stores out inputs and targets. A custom Dataset class must implement three functions: `__init__`, `__len__`, and `__getitem__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = pd.read_csv(data_file)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['review']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset('data/review_train.csv')\n",
    "test_dataset = CustomDataset('data/review_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:  what kids will discover is a new collectible . what parents will suspect is that they're watching a 76-minute commercial . \n",
      "Label:  0\n"
     ]
    }
   ],
   "source": [
    "# Look at a sample review and label\n",
    "idx = 28\n",
    "print(\"Review: \", train_dataset.__getitem__(idx)[0])\n",
    "print(\"Label: \", train_dataset.__getitem__(idx)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data processing pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `torchtext` package to simplify the process of preprocessing as it provides utilities and tools for working with text data. If you don't have it installed yet, you can install it using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text pipeline is used to process the raw data strings from the dataset iterators. We need a tokenizer to divide text into individual units (call tokens) and a vocabulary which maps each unique token to a numerical index. The pipeline is then converts a text string into a list of integers based on the lookup table defined in the vocabulary.\n",
    "\n",
    "Concepts:\n",
    "- **Tokenization**: refers to the process of dividing a text or sentence into smaller components known as tokens. A token is often a individual word but can also be character, subword, or other meaningful element of text. Tokenization can present challenges, such as dealing with contractions (e.g., splitting \"can't\" into \"can\" and \"'t\") or punctuation (\"Mr. Smith\" treated as [\"Mr\", \".\", \"Smith\"])\n",
    "- **Special Tokens**:\n",
    "    - `<pad>`: padding token, typically assigned the index 0. While training, a model we mostly train in batches. In a batch, there can be sentences of different length. So, we pad the shorter sentences with `<pad>` token to make length of all sequences in the batch equal.\n",
    "    - `<unk>`: unknown token which is used when a model encounters a word it hasn't seen during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code demonstrates how to build a vocabulary from a dataset using tokenization and special tokens, and then transform text into a sequence of integers based on the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "0.18.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "print(torch.__version__)\n",
    "print(torchtext.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  8459\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\", language=\"en\")\n",
    "min_word_freq=2 # Words must appear at least twice to be included in the vocabulary\n",
    "PAD_TOKEN = '<pad>' # padding token\n",
    "UNK_TOKEN = '<unk>' # unknown token\n",
    "SPECIALS = [PAD_TOKEN, UNK_TOKEN]\n",
    "\n",
    "def build_vocab(dataset, tokenizer):\n",
    "    texts = [text for text , _ in dataset]\n",
    "    vocab = build_vocab_from_iterator(\n",
    "        map(tokenizer, texts),\n",
    "        specials=SPECIALS,\n",
    "        min_freq=min_word_freq\n",
    "    )\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "    return vocab\n",
    "\n",
    "vocab = build_vocab(train_dataset,tokenizer)\n",
    "vocab_size = vocab.__len__()\n",
    "print(\"Vocabulary size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 167, 204]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The pipeline is a lambda function that takes an string x\n",
    "# and applies two transformations: tokenize the input and then\n",
    "# maps each token to its corresponding index from the vocabulary.\n",
    "# \n",
    "# When the string 'Hello world!' is passed to the pipeline, \n",
    "# it is tokenized into ['hello', 'world', '!'].\n",
    "# \n",
    "# The output [1, 167, 204] indicates that 'Hello' maps to index 1, \n",
    "# 'world' to 167, and '!' is mapped to index 204.\n",
    "#  \n",
    "# Because 1 is unknown token (<unk>), it suggests 'hello' is not in the vocabulary.\n",
    "# In other words, 'hello' is not present in the training data.\n",
    "\n",
    "pipeline = lambda x : vocab(tokenizer(x))\n",
    "pipeline('Hello world!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collation\n",
    "\n",
    "When working with text data, sentences or sequences of text often have variable lengths. Since models expect all inputs in a batch to have the same length, we need to convert these variable-length sequences into batched tensors by padding the shorter sequences.\n",
    "\n",
    "Although RNNs can process sequences of any length (as long as all sequences within a batch share the same length), it's often beneficial to cap the maximum sequence length. This reduces computational complexity and prevent vanishing gradients. Longer sequences can lead to vanishing gradients, making training more difficult.\n",
    "\n",
    "By restricting the sequence to a predefined `MAX_LENGTH`, we assume that the key sentiment or message is captured early in the review.\n",
    "\n",
    "In the code cell below, we set `MAX_LENGTH` to 100, but feel free to play with this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 100\n",
    "def collator(batch):\n",
    "    \"\"\"\n",
    "    Process a batch of text-label pairs, transform the text into a tensor, \n",
    "    and pad the sequences to have the same length capped by MAX_LENGTH.\n",
    "\n",
    "    Args: \n",
    "        list of (text, label) pair \n",
    "    \n",
    "    Returns: \n",
    "        A pair of tensors:\n",
    "        - texts: a tensor of tokenized texts.\n",
    "        - labels: a tensor of labels.\n",
    "    \"\"\"\n",
    "    # Unzip the batch into sequences and labels\n",
    "    sequences, labels = zip(*batch)\n",
    "    # Apply a pipeline to each sequence and truncate to MAX_LENGTH\n",
    "    truncated_seqs = [pipeline(seq)[:MAX_LENGTH] for seq in sequences]\n",
    "    # Convert to tensor type int64 (needed as nn.Embedding takes input of IntTensor or LongTensor)\n",
    "    truncated_seqs = [torch.tensor(seq, dtype=torch.int64) for seq in truncated_seqs]\n",
    "    # Pad the sequences so they all have the same length and stack them into a single tensor\n",
    "    texts = pad_sequence(truncated_seqs, batch_first=True, padding_value=0)\n",
    "    # Convert the labels into a IntTensor (commonly used for classification)\n",
    "    labels = torch.tensor(labels, dtype=torch.int64)\n",
    "    \n",
    "    return texts , labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `collate_fn` in DataLoader is used to customize how individual samples from the dataset are combined into batches. By using a `collator` function implemented above, it ensures that each batch is processed consistently, handling necessary transformations and padding as required for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, collate_fn=collator)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Building the Text Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/text_classification_model.png\" style=\"width:400;height:300px\"></center>\n",
    "\n",
    "Architecture of our model:\n",
    "$$x \\rightarrow \\text{Embedding} \\rightarrow \\text{LSTM} \\rightarrow \\text{Linear}(2) \\rightarrow \\text{output}$$\n",
    "\n",
    "- `nn.Embedding`: The embedding layer converts each word (represented by an index) into dense vectors of `embed_size`. It learns word representations during training. To define an embedding layer, you need to specify the size of the vocabulary and the dimension of the embedding vectors.\n",
    "- `nn.LSTM`: To define an LSTM layer, you need to specify the input size (the number of features in the input), the hidden size (the dimension of the hidden state). This layer return hidden states for all time steps and a tuple consisting of the last hidden and cell states.\n",
    "- `nn.Linear`: a fully-connected layer with the specified input and output features. In this case the output size is `num_class` = 2.\n",
    "\n",
    "__Note:__ For all your networks hereon, the only constructor argument is `classes`. Do not add any other parameters to the `__init__` method. Remember not to hardcode for the number of classes and use the `classes` argument instead. For LSTM layer, use `batch_first=True` to ensure that the batch dimension is handled as the first input dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_size, num_class):\n",
    "        super().__init__()\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, batch_first=True)\n",
    "        self.l1 = nn.Linear(hidden_size, num_class)\n",
    "        self.softmax = nn.Sigmoid()\n",
    "        \"\"\" YOUR CODE END HERE \"\"\"\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        x = self.embed(x)\n",
    "        #take output of hidden state\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.l1(x)[:,-1,:]\n",
    "        return x\n",
    "        \"\"\" YOUR CODE END HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "model = TextClassificationModel(10, 5, 6, 2)\n",
    "assert [layer.detach().numpy().shape for _, layer in model.named_parameters()] \\\n",
    "        == [(10, 5), (24, 5), (24, 6), (24,), (24,), (2, 6), (2,)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m num_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      4\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m TextClassificationModel(vocab_size , embed_dim, hidden_size, num_class)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      7\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(params \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mparameters() , lr\u001b[38;5;241m=\u001b[39mlr)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 779\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[0;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1154\u001b[0m             device,\n\u001b[0;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1156\u001b[0m             non_blocking,\n\u001b[0;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1158\u001b[0m         )\n\u001b[1;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1160\u001b[0m         device,\n\u001b[0;32m   1161\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1162\u001b[0m         non_blocking,\n\u001b[0;32m   1163\u001b[0m     )\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 300\n",
    "hidden_size = 128\n",
    "num_class = 2\n",
    "lr = 0.001\n",
    "model = TextClassificationModel(vocab_size , embed_dim, hidden_size, num_class).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params = model.parameters() , lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[133], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m num_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m texts, labels \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m----> 8\u001b[0m     texts, labels \u001b[38;5;241m=\u001b[39m texts\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)  \n\u001b[0;32m      9\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(texts)\n\u001b[0;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "model.train()\n",
    "for epoch in range(num_epochs):  \n",
    "    epoch_loss = 0.0  \n",
    "    num_correct = 0\n",
    "\n",
    "    for texts, labels in train_dataloader:\n",
    "        texts, labels = texts.to(device), labels.to(device)  \n",
    "        output = model(texts)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        epoch_loss += loss.item() \n",
    "        num_correct += (output.argmax(1) == labels).sum().item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss /= len(train_dataloader)  \n",
    "    epoch_acc = (num_correct / len(train_dataloader.dataset)) * 100  \n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[134], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m texts, labels \u001b[38;5;129;01min\u001b[39;00m test_dataloader:\n\u001b[1;32m----> 6\u001b[0m         texts, labels \u001b[38;5;241m=\u001b[39m texts\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(texts) \n\u001b[0;32m      8\u001b[0m         predictions \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model.eval()  \n",
    "num_correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for texts, labels in test_dataloader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        output = model(texts) \n",
    "        predictions = output.argmax(1)\n",
    "        num_correct += (predictions == labels).sum().item()  \n",
    "\n",
    "eval_acc = (num_correct / len(test_dataloader.dataset)) * 100\n",
    "print(f\"Validation Accuracy: {eval_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_text):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = torch.tensor(pipeline(input_text)).to(device)\n",
    "        output = model(tokens)\n",
    "        prediction = output.argmax()\n",
    "        return \"positive\" if prediction== 1 else \"negative\"\n",
    "\n",
    "my_review = \"Write your review here\"\n",
    "predict(my_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Once you are done, please submit your work to Coursemology, by copying the right snippets of code into the corresponding box that says \"Your answer,\"and click \"Save.\" After you save, you can still make changes to your submission.\n",
    "\n",
    "Once you are satisfied with what you have uploaded, click \"Finalize submission.\" Note that once your submission is finalized, it is considered to be submitted for grading and cannot be changed. If you need to undo this action, you will have to email your assigned tutor for help. Please do not finalize your submission until you are sure that you want to submit your solutions for grading.\n",
    "\n",
    "*Have fun and enjoy coding.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
