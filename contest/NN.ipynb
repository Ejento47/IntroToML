{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN for Connect 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 26, 'name': 'Connect-4', 'repository_url': 'https://archive.ics.uci.edu/dataset/26/connect+4', 'data_url': 'https://archive.ics.uci.edu/static/public/26/data.csv', 'abstract': 'Contains connect-4 positions', 'area': 'Games', 'tasks': ['Classification'], 'characteristics': ['Multivariate', 'Spatial'], 'num_instances': 67557, 'num_features': 42, 'feature_types': ['Categorical'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1995, 'last_updated': 'Sat Mar 09 2024', 'dataset_doi': '10.24432/C59P43', 'creators': ['John Tromp'], 'intro_paper': None, 'additional_info': {'summary': 'This database contains all legal 8-ply positions in the game of connect-4 in which neither player has won yet, and in which the next move is not forced.\\r\\n\\r\\nx is the first player; o the second.\\r\\n\\r\\nThe outcome class is the game theoretical value for the first player.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Attribute Information: (x=player x has taken, o=player o has taken, b=blank)\\r\\n\\r\\nThe board is numbered like:\\r\\n6 . . . . . . .\\r\\n5 . . . . . . .\\r\\n4 . . . . . . .\\r\\n3 . . . . . . .\\r\\n2 . . . . . . .\\r\\n1 . . . . . . .\\r\\n a b c d e f g\\r\\n\\r\\n    1. a1: {x,o,b}\\r\\n    2. a2: {x,o,b}\\r\\n    3. a3: {x,o,b}\\r\\n    4. a4: {x,o,b}\\r\\n    5. a5: {x,o,b}\\r\\n    6. a6: {x,o,b}\\r\\n    7. b1: {x,o,b}\\r\\n    8. b2: {x,o,b}\\r\\n    9. b3: {x,o,b}\\r\\n   10. b4: {x,o,b}\\r\\n   11. b5: {x,o,b}\\r\\n   12. b6: {x,o,b}\\r\\n   13. c1: {x,o,b}\\r\\n   14. c2: {x,o,b}\\r\\n   15. c3: {x,o,b}\\r\\n   16. c4: {x,o,b}\\r\\n   17. c5: {x,o,b}\\r\\n   18. c6: {x,o,b}\\r\\n   19. d1: {x,o,b}\\r\\n   20. d2: {x,o,b}\\r\\n   21. d3: {x,o,b}\\r\\n   22. d4: {x,o,b}\\r\\n   23. d5: {x,o,b}\\r\\n   24. d6: {x,o,b}\\r\\n   25. e1: {x,o,b}\\r\\n   26. e2: {x,o,b}\\r\\n   27. e3: {x,o,b}\\r\\n   28. e4: {x,o,b}\\r\\n   29. e5: {x,o,b}\\r\\n   30. e6: {x,o,b}\\r\\n   31. f1: {x,o,b}\\r\\n   32. f2: {x,o,b}\\r\\n   33. f3: {x,o,b}\\r\\n   34. f4: {x,o,b}\\r\\n   35. f5: {x,o,b}\\r\\n   36. f6: {x,o,b}\\r\\n   37. g1: {x,o,b}\\r\\n   38. g2: {x,o,b}\\r\\n   39. g3: {x,o,b}\\r\\n   40. g4: {x,o,b}\\r\\n   41. g5: {x,o,b}\\r\\n   42. g6: {x,o,b}\\r\\n   43. Class: {win,loss,draw}', 'citation': None}}\n",
      "     name     role         type demographic description units missing_values\n",
      "0      a1  Feature  Categorical        None        None  None             no\n",
      "1      a2  Feature  Categorical        None        None  None             no\n",
      "2      a3  Feature  Categorical        None        None  None             no\n",
      "3      a4  Feature  Categorical        None        None  None             no\n",
      "4      a5  Feature  Categorical        None        None  None             no\n",
      "5      a6  Feature  Categorical        None        None  None             no\n",
      "6      b1  Feature  Categorical        None        None  None             no\n",
      "7      b2  Feature  Categorical        None        None  None             no\n",
      "8      b3  Feature  Categorical        None        None  None             no\n",
      "9      b4  Feature  Categorical        None        None  None             no\n",
      "10     b5  Feature  Categorical        None        None  None             no\n",
      "11     b6  Feature  Categorical        None        None  None             no\n",
      "12     c1  Feature  Categorical        None        None  None             no\n",
      "13     c2  Feature  Categorical        None        None  None             no\n",
      "14     c3  Feature  Categorical        None        None  None             no\n",
      "15     c4  Feature  Categorical        None        None  None             no\n",
      "16     c5  Feature  Categorical        None        None  None             no\n",
      "17     c6  Feature  Categorical        None        None  None             no\n",
      "18     d1  Feature  Categorical        None        None  None             no\n",
      "19     d2  Feature  Categorical        None        None  None             no\n",
      "20     d3  Feature  Categorical        None        None  None             no\n",
      "21     d4  Feature  Categorical        None        None  None             no\n",
      "22     d5  Feature  Categorical        None        None  None             no\n",
      "23     d6  Feature  Categorical        None        None  None             no\n",
      "24     e1  Feature  Categorical        None        None  None             no\n",
      "25     e2  Feature  Categorical        None        None  None             no\n",
      "26     e3  Feature  Categorical        None        None  None             no\n",
      "27     e4  Feature  Categorical        None        None  None             no\n",
      "28     e5  Feature  Categorical        None        None  None             no\n",
      "29     e6  Feature  Categorical        None        None  None             no\n",
      "30     f1  Feature  Categorical        None        None  None             no\n",
      "31     f2  Feature  Categorical        None        None  None             no\n",
      "32     f3  Feature  Categorical        None        None  None             no\n",
      "33     f4  Feature  Categorical        None        None  None             no\n",
      "34     f5  Feature  Categorical        None        None  None             no\n",
      "35     f6  Feature  Categorical        None        None  None             no\n",
      "36     g1  Feature  Categorical        None        None  None             no\n",
      "37     g2  Feature  Categorical        None        None  None             no\n",
      "38     g3  Feature  Categorical        None        None  None             no\n",
      "39     g4  Feature  Categorical        None        None  None             no\n",
      "40     g5  Feature  Categorical        None        None  None             no\n",
      "41     g6  Feature  Categorical        None        None  None             no\n",
      "42  class   Target  Categorical        None        None  None             no\n"
     ]
    }
   ],
   "source": [
    "# fetch dataset \n",
    "connect_4 = fetch_ucirepo(id=26) \n",
    "# metadata \n",
    "print(connect_4.metadata)  \n",
    "# variable information \n",
    "print(connect_4.variables) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67557, 42)\n",
      "(67557, 1)\n"
     ]
    }
   ],
   "source": [
    "# data (as pandas dataframes) \n",
    "X = connect_4.data.features \n",
    "y = connect_4.data.targets \n",
    "#intepret connect 4 dataset\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# print(X.iloc[0,:])\n",
    "# print(y.iloc[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding X and y \n",
    "This is to helping with normalizing data and making it easier to work with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67557, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johna\\AppData\\Local\\Temp\\ipykernel_25976\\3232681351.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_r = X.replace({'x':1,'o':2,'b':0})\n",
      "C:\\Users\\johna\\AppData\\Local\\Temp\\ipykernel_25976\\3232681351.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y_r = y.replace({'win':2,'draw':1,'loss':0})\n"
     ]
    }
   ],
   "source": [
    "#Since x data are categorical, we need to encode them\n",
    "\n",
    "#X -> x = 1 , o = -1 , b = 0\n",
    "X_r = X.replace({'x':1,'o':2,'b':0})\n",
    "#y -> win = 1 , draw = 0, loss = -1\n",
    "y_r = y.replace({'win':2,'draw':1,'loss':0})\n",
    "print(y_r.shape)\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_r, y_r, test_size=0.2, random_state=42)\n",
    "# Convert pandas dataframes to PyTorch tensors, do not use dataloader\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long).squeeze()\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.long).squeeze()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SKlearns random forest classifier to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8203\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SKlearn logistic regression to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6576\n"
     ]
    }
   ],
   "source": [
    "#try with different models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SKlearn MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johna\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#use NN\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nn for connect 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss: 0.4500786323919364\n",
      "Epoch 20, loss: 0.3916770363882642\n",
      "Epoch 30, loss: 0.35550200657359815\n",
      "Epoch 40, loss: 0.33053254295607265\n",
      "Epoch 50, loss: 0.3142285339939397\n",
      "Epoch 60, loss: 0.296659553128495\n",
      "Epoch 70, loss: 0.279640196027767\n",
      "Epoch 80, loss: 0.2660755416462044\n",
      "Epoch 90, loss: 0.25703442484210853\n",
      "Epoch 100, loss: 0.24564706749033985\n",
      "Accuracy: 0.8188\n"
     ]
    }
   ],
   "source": [
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define a simple neural network\n",
    "class Connect4NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Connect4NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 128)\n",
    "        self.droupout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 3)\n",
    "        self.relu = nn.ReLU() #rmb cross entropy already has softmax\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "model = Connect4NN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    runningloss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runningloss += loss.item()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, loss: {runningloss/len(train_loader)}')\n",
    "    \n",
    "# Test the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        y_pred = model(X_batch)\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        total += y_batch.size(0) #0 is the number of elements in the tensor\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "print(f'Accuracy: {correct/total:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'fc1.weight': array([[-0.9172921 ,  0.01317978,  0.04196112, ...,  0.10881053,\n",
      "        -0.18134035,  0.02382498],\n",
      "       [-0.11771316, -0.09623528, -0.07955053, ...,  0.04455304,\n",
      "        -0.2419225 ,  0.05795357],\n",
      "       [-0.08505697, -0.20643847,  0.2649403 , ..., -0.22551998,\n",
      "         0.33757955,  0.05375292],\n",
      "       ...,\n",
      "       [-0.1371001 , -0.12976906,  0.02088212, ..., -0.13445982,\n",
      "        -0.1397467 , -0.03763557],\n",
      "       [ 0.01979042, -0.09754016,  0.03448568, ...,  0.07651879,\n",
      "         0.11732315,  0.02098016],\n",
      "       [-0.05844294, -0.0510306 , -0.41637105, ...,  0.03920374,\n",
      "         0.37483162, -0.03420401]], dtype=float32), 'fc1.bias': array([-0.01853321, -0.05241129,  0.10026716, -0.12027285,  0.0133744 ,\n",
      "       -0.1389007 , -0.05916514, -0.03272083, -0.13664131,  0.08095073,\n",
      "       -0.09348211, -0.15980193, -0.125313  , -0.16184181, -0.1466474 ,\n",
      "       -0.11890833,  0.0019084 , -0.14425734,  0.04845731,  0.13099606,\n",
      "        0.04800085, -0.08505814, -0.00918544, -0.08592399, -0.03481103,\n",
      "        0.1271725 ,  0.05624298, -0.17016375,  0.06614812, -0.06266979,\n",
      "       -0.05124571, -0.00631893, -0.04451537,  0.0206791 , -0.00515495,\n",
      "       -0.02798569, -0.13896887, -0.01585724,  0.12349401, -0.17344052,\n",
      "       -0.13142681, -0.11738884,  0.09890106, -0.09215362, -0.10262784,\n",
      "       -0.0573635 ,  0.04692028,  0.02219   , -0.16165783, -0.11979094,\n",
      "       -0.14371796, -0.06455449, -0.13238999, -0.07544552, -0.05653882,\n",
      "        0.11615361, -0.06728408, -0.04154699, -0.0479816 , -0.11756253,\n",
      "        0.13024934,  0.0795588 , -0.09903445, -0.0681418 , -0.13274927,\n",
      "       -0.1352719 , -0.12362456, -0.0737299 , -0.10094501, -0.09239971,\n",
      "        0.07525003, -0.11835416, -0.05241318,  0.03389381, -0.08392487,\n",
      "       -0.0667301 , -0.19389555,  0.11024875,  0.12435815, -0.03099512,\n",
      "        0.02265045,  0.00229005, -0.20140333, -0.00102048,  0.10851966,\n",
      "       -0.13187692, -0.0348299 , -0.16710751, -0.09754545, -0.17212114,\n",
      "       -0.15994501,  0.12796831, -0.021954  , -0.1523973 ,  0.01608987,\n",
      "        0.09562531,  0.07435062,  0.00786744, -0.16658022, -0.05126941,\n",
      "        0.09682489,  0.0135083 , -0.12755609, -0.04770703, -0.00567078,\n",
      "        0.02651199, -0.07460657, -0.03735567, -0.18136404, -0.03023132,\n",
      "       -0.13497916, -0.02498118,  0.01591765, -0.16980492,  0.02800673,\n",
      "       -0.1009174 ,  0.02293841, -0.23461442,  0.05290955,  0.07323208,\n",
      "       -0.11757478,  0.10401054,  0.07240185, -0.01017191, -0.03576119,\n",
      "       -0.06785149, -0.05677868, -0.0956971 ], dtype=float32), 'fc2.weight': array([[-0.02165428,  0.09299137,  0.15665744, ..., -0.11528115,\n",
      "        -0.18624656, -0.13008279],\n",
      "       [-0.13529414, -0.03679138, -0.13083659, ...,  0.19601329,\n",
      "        -0.3620187 ,  0.05011036],\n",
      "       [ 0.02854906, -0.06189649,  0.07023395, ...,  0.10965581,\n",
      "        -0.10413685,  0.19990362],\n",
      "       ...,\n",
      "       [-0.07406993, -0.12316427,  0.08939108, ...,  0.3466989 ,\n",
      "        -0.40637225,  0.0451065 ],\n",
      "       [ 0.1499741 , -0.29977536,  0.0395152 , ..., -0.6891988 ,\n",
      "        -0.40734464,  0.19601025],\n",
      "       [-0.08232119,  0.00281856, -0.20849296, ..., -0.05193891,\n",
      "        -0.3479066 ,  0.31918156]], dtype=float32), 'fc2.bias': array([-0.10364971,  0.05606419, -0.01041927,  0.04030516, -0.10233118,\n",
      "       -0.09981021, -0.09308544,  0.04026293, -0.07681774, -0.10100438,\n",
      "        0.10748874, -0.20514673,  0.02900665,  0.02190302, -0.0357423 ,\n",
      "        0.12424973, -0.10854989, -0.06772356, -0.00307824,  0.05033344,\n",
      "        0.11637706, -0.07708149, -0.05415165,  0.04199989, -0.02011473,\n",
      "        0.16297822, -0.05688857,  0.00208565,  0.0509159 , -0.03592324,\n",
      "        0.00646316, -0.09660508, -0.01451717,  0.06220796,  0.03719041,\n",
      "       -0.06171603,  0.00577017, -0.03808248,  0.05590383,  0.0530766 ,\n",
      "       -0.0194165 ,  0.0868348 , -0.12180982,  0.0007098 , -0.00692053,\n",
      "        0.00516235, -0.04931077, -0.1374632 , -0.06430448, -0.04779005,\n",
      "       -0.08161338, -0.17455906, -0.06337863, -0.06720636, -0.02334681,\n",
      "        0.08915823,  0.03720802, -0.1204553 ,  0.08379505, -0.08760902,\n",
      "        0.04503002, -0.01647864,  0.07246214, -0.03026745], dtype=float32), 'fc3.weight': array([[ 0.05572069, -0.14540657, -0.30558446, ..., -0.8781912 ,\n",
      "        -0.4651009 ,  0.48378477],\n",
      "       [-0.20133747,  0.04089162, -0.02808891, ..., -0.3527779 ,\n",
      "        -0.00506877,  0.25853115],\n",
      "       [-0.03644319,  0.07517003,  0.01158689, ...,  0.10158547,\n",
      "         0.20716111,  0.10961536],\n",
      "       ...,\n",
      "       [ 0.06876865,  0.09867425, -0.26793477, ...,  0.25275433,\n",
      "        -0.09055292, -0.08311844],\n",
      "       [-0.01987511, -0.34497374, -0.3019413 , ..., -0.6241568 ,\n",
      "         0.00234947, -0.07575062],\n",
      "       [ 0.12523584,  0.16581409, -0.06886897, ...,  0.26843283,\n",
      "        -0.26045913,  0.05182798]], dtype=float32), 'fc3.bias': array([ 0.03553071, -0.16073039,  0.07719301, -0.14312008,  0.02199409,\n",
      "       -0.04931564,  0.19314113,  0.0791533 ,  0.1214454 ,  0.16896132,\n",
      "       -0.14430988,  0.18893202, -0.0871321 ,  0.04506213, -0.04289276,\n",
      "        0.11286102,  0.04216987, -0.06512737, -0.02978755, -0.00251008,\n",
      "        0.19281279, -0.05661077, -0.04001294,  0.1995231 ,  0.08414119,\n",
      "        0.23679002, -0.20906761,  0.19691835, -0.06800149, -0.19424173,\n",
      "        0.28745526, -0.04490973], dtype=float32), 'fc4.weight': array([[ 0.4721661 ,  0.04660553, -0.40007898,  0.09444013, -0.3078266 ,\n",
      "         0.46760437, -0.4669753 ,  0.23313786,  0.08479728, -0.0206714 ,\n",
      "        -0.03198265, -0.18141806,  0.5371084 ,  0.12148678,  0.21800065,\n",
      "        -0.307089  , -0.33050212, -0.58408153,  0.22845124,  0.7649696 ,\n",
      "        -0.4383639 ,  0.24726656, -0.64669013, -0.48621705,  0.182581  ,\n",
      "        -0.3485809 , -0.07357314, -0.16797364, -0.32436395,  0.14324266,\n",
      "        -0.0833017 ,  0.26034138],\n",
      "       [ 0.29157192, -0.1432343 , -0.53813213, -0.1662958 , -0.0149571 ,\n",
      "        -0.1322766 , -0.34061775, -0.06095678,  0.41345766, -0.05331566,\n",
      "        -0.09280375,  0.0410695 , -0.30229095, -0.3203547 , -0.03260841,\n",
      "        -0.39415738, -0.09008535,  0.53808874, -0.27168518, -0.56430787,\n",
      "         0.21210083, -0.3947865 , -0.6141527 ,  0.3022508 , -0.16642453,\n",
      "        -0.1934597 , -0.19487616, -0.37283567, -0.6658067 , -0.5482286 ,\n",
      "         0.7347272 , -0.28507447],\n",
      "       [-0.6899249 , -0.19962735,  0.697432  , -0.07457475,  0.33697975,\n",
      "        -0.6742117 ,  0.63168585, -0.3053608 , -0.7020685 ,  0.24490543,\n",
      "         0.10012215,  0.28703672, -0.23425868,  0.1832236 , -0.30656502,\n",
      "         0.340053  ,  0.20979007, -0.25831845,  0.16689922, -0.3812229 ,\n",
      "         0.12147187, -0.36309674,  0.8032968 , -0.06893705, -0.09413984,\n",
      "         0.52489895, -0.09247987,  0.07527941,  0.35462707,  0.08938594,\n",
      "        -0.3323818 ,  0.02989718]], dtype=float32), 'fc4.bias': array([-0.20695354,  0.21208565,  0.11214517], dtype=float32)})\n"
     ]
    }
   ],
   "source": [
    "#save model weights as numpy array\n",
    "model_weights = model.state_dict()\n",
    "for key in model_weights:\n",
    "    model_weights[key] = model_weights[key].numpy()\n",
    "print(model_weights)\n",
    "\n",
    "#i want to save the model weights and copy is direcly \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model weights as numpy array in a file\n",
    "import numpy as np\n",
    "np.save('model_weights.npy', model_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#test on first y_test\n",
    "model.eval()\n",
    "print(y_test[1])\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test[1])\n",
    "    _, predicted = torch.max(y_pred, 0)\n",
    "    print(predicted.item())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
