{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2: Local & Adversarial Search\n",
    "\n",
    "**Release Date:** 2 September 2024\n",
    "\n",
    "**Due Date:** 23:59, 14 September 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In class, we discussed a range of search algorithms. In this problem set, we will get some hands-on practice by implementing local search for the **Travelling Salesman Problem (TSP)**, which operates in a fully-observable, single-agent, deterministic, episodic, static, and discrete environment. We will also get some hands-on practice on Adversarial Search by coding an AI to play the game **Breakthrough**.\n",
    "\n",
    "**Required Files**:\n",
    "* ps2.py\n",
    "* breakthrough.py\n",
    "\n",
    "**Plagiarism Policy**: Please refer to our [Course Policies](https://canvas.nus.edu.sg/courses/62323/pages/course-policies)\n",
    "\n",
    "**IMPORTANT**: While it is possible to write and run Python code directly in Jupyter notebook, we recommend that you do this Problem set with an IDE using the .py file provided. An IDE will make debugging significantly easier.\n",
    "\n",
    "**Post-Problem Set Survey**:\n",
    "Your feedback is important to us! After completing Problem Set 2, please take a moment to share your thoughts by filling out this [survey](https://coursemology.org/courses/2851/surveys/2387)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Travelling Salesman Problem (TSP)\n",
    "\n",
    "Your cousin Ben Bitdiddle is planning to start a company which sells premium imported chocolate from Europe. Among all cities in the country, Ben must choose one to be his company headquarters to receive shipment from Europe and devise a route from the headquarters to deliver the chocolate to every other city. This route must only visit each city **exactly once** and return to the headquarters to receive the next shipment. In addition, to save fuel cost, the route must be **as short as possible**. Given a list of cities and the distance between every two cities, what is the shortest possible route?\n",
    "\n",
    "This problem is a classic NP-hard optimisation problem in computer science. In this task, you will design and implement a local search algorithm to find a shortest route. You must find the route as **a list of cities** in the order of travel from the starting city to the last city before returning.\n",
    "\n",
    "For example, consider the graph below, which represents 4 cities and the distances between them.\n",
    "\n",
    "<pre>\n",
    "<p style=\"text-align: center;\">\n",
    "<img src=\"images/tsp.png\", width = 400>\n",
    "</pre>\n",
    "\n",
    "An optimal route is `[0, 1, 2, 3]`, with the minimal distance travelled of 1 + 2 + 2 + 3 = 8.\n",
    "\n",
    "**Note:**\n",
    "* There can be more than 1 shortest route, e.g., `[1, 0, 3, 2]`, `[1, 3, 2, 0]`, etc. You only need to find one such route.\n",
    "* `[0, 1, 2]` is not legal as the route must go through all 4 cities.\n",
    "* `[0, 1, 2, 3, 1]` is not legal as city 1 is visited more than once.\n",
    "* `[1, 3, 0, 2]` is legal but it is not the shortest route, as the distance travelled of 3 + 3 + 2 + 2 = 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: State representation\n",
    "Propose a state representation for this problem if we want to formulate it as a local search problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: Initial and goal states\n",
    "\n",
    "What are the initial and goal states for the problem under your proposed representation?\n",
    "\n",
    "**Note:**\n",
    "* In many optimization problems such as the TSP, the path to the goal is irrelevant; **the goal state itself is the solution to the problem**.\n",
    "* Local search algorithms keep a single \"current\" state and move from a state to another in the search space by applying local changes (with the help of a *transition function*), until an optimal solution is found."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you do better?\n",
    "\n",
    "Recall that similar to A* search, local search utilises evaluation functions to decide how to transition from one state to another. However, being an uninformed guy, your cousin Ben Bitdiddle tells you to use the \"greedy\" solution. Given an incomplete route, the \"greedy\" solution builds a path by adding the closest unvisited node from the last visited node, until all nodes are visited. For instance, in the graph above, the \"greedy\" solution is `[0, 1, 2, 3]`.\n",
    "\n",
    "Although this solution seems relatively sensible, as a CS2109S student, you have a nagging feeling that it may not work all the time. Can you create an evaluation function and transition function to get better results with local search?\n",
    "\n",
    "\n",
    "**Note:**\n",
    "\n",
    "* For the following tasks, we will be benchmarking your hill-climbing algorithm against our own version using the greedy solution. Note that the hidden test cases can be quite large, so any brute-force solution will not suffice. \n",
    "\n",
    "* Your own evaluation functions and transition functions may underperform against the greedy solution for small instances of TSP, but should outperform the greedy solution consistently for large instances. For our public and private test cases, we have designed the greedy solution to be suboptimal.\n",
    "\n",
    "* If your code does not pass the private test cases on Coursemology because it underperforms against the greedy solution, you may re-run your code a few times in case you are \"unlucky\" with random initial routes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3: State transitions\n",
    "\n",
    "Implement a reasonable transition function `transition(route)` to generate new routes by applying minor \"tweaks\" to the current route. It should return a list of new routes to be used in the next iteration in the hill-climbing algorithm.\n",
    "\n",
    "**Note:**\n",
    "* At each iteration, the routes generated from the transition function are evaluated against each other (using an evaluation function). The best route will be selected for the next iteration if it is better than the current route.\n",
    "* Your transition function should not return too many routes as it would take too much time for evaluation. (do not enumerate all possible states otherwise it will timeout, only generate \"neighbors\")\n",
    "* However, if too few routes are generated, you are more likely to be stuck at a local maxima as each route will be compared against fewer routes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the following cell before proceeding. You may use any of the imported libraries/classes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run this cell before you start!\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from typing import List, Tuple, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(route: List[int]) -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    Generates new routes to be used in the next iteration in the hill-climbing algorithm.\n",
    "\n",
    "    Args:\n",
    "        route (List[int]): The current route as a list of cities in the order of travel.\n",
    "\n",
    "    Returns:\n",
    "        new_routes (List[List[int]]): New routes to be considered.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "# Test cases\n",
    "def test_transition(route):\n",
    "    sorted_route = sorted(route)\n",
    "    result = transition(route)\n",
    "    assert result is not None, \"Transition function returns an empty list.\"\n",
    "    assert any(result), \"Transition function returns an empty list.\"\n",
    "    for new_route in result:\n",
    "        assert len(new_route) == len(sorted_route), \"New route does not have the same number of cities as the original route.\"\n",
    "        assert sorted(new_route) == sorted_route, \"New route does not contain all cities present in the original route.\"\n",
    "\n",
    "permutation_route = [0, 1, 2, 3, 4]\n",
    "new_permutation_routes = transition(permutation_route)\n",
    "assert len(new_permutation_routes) < 24, \"Your transition function may have generated too many new routes by enumerating all possible states.\"\n",
    "\n",
    "test_transition([1, 3, 2, 0])\n",
    "test_transition([7, 8, 6, 3, 5, 4, 9, 2, 0, 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.4: Evaluation function\n",
    "Implement an evaluation function `evaluation_func(cities, distances, route)` that would be helpful in deciding on the \"goodness\" of a route, i.e. an optimal route should return a higher evaluation score than a suboptimal one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_func(\n",
    "    cities: int,\n",
    "    distances: List[Tuple[int]],\n",
    "    route: List[int]\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Computes the evaluation score of a route\n",
    "\n",
    "    Args:\n",
    "        cities (int): The number of cities to be visited.\n",
    "\n",
    "        distances (List[Tuple[int]]): The list of distances between every two cities. Each distance\n",
    "            is represented as a tuple in the form of (c1, c2, d), where c1 and c2 are the two cities\n",
    "            and d is the distance between them. The length of the list should be equal to cities *\n",
    "            (cities - 1)/2.\n",
    "\n",
    "        route (List[int]): The current route as a list of cities in the order of travel.\n",
    "\n",
    "    Returns:\n",
    "        h_n (float): the evaluation score.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "# Test cases\n",
    "cities = 4\n",
    "distances = [(1, 0, 10), (0, 3, 22), (2, 1, 8), (2, 3, 30), (1, 3, 25), (0, 2, 15)]\n",
    "\n",
    "route_1 = evaluation_func(cities, distances, [0, 1, 2, 3])\n",
    "route_2 = evaluation_func(cities, distances, [2, 1, 3, 0])\n",
    "route_3 = evaluation_func(cities, distances, [1, 3, 2, 0])\n",
    "\n",
    "assert route_1 == route_2\n",
    "assert route_1 > route_3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.5: Explain your evaluation function\n",
    "\n",
    "Explain why your evaluation function is suitable for this problem. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.6: Implement hill-climbing\n",
    "Using your representation above, implement the hill-climbing algorithm `hill_climbing(cities, distances, transition, evaluation_func)`, which takes in the number of cities and the list of distances, a transition function, an evaluation function and returns the shortest route as a list of cities.\n",
    "\n",
    "1. The hill-climbing approach is a local search algorithm which starts with a randomly-initialised state and continuously selects the next candidate solution that locally maximizes the reduction of the evaluation function.\n",
    "\n",
    "2. The algorithm terminates when a (local) maxima is reached, i.e. a solution that cannot be improved further by looking at the next candidate solutions.\n",
    "\n",
    "3. Unlike previous search algorithms you have implemented, hill-climbing only keeps a single current state. As such, it does not involve a search tree/graph. Backtracking is also not possible.\n",
    "\n",
    "Coursemology will tests this question with correct implementation of `transition(route)` and `evaluation_func(cities, distances, route)`, in case you were unable to come up with a good evaluation function and transition function. Note that the implemented `evaluation_func(cities, distances, route)` returns a float, which can be from `float(-inf)` to `float(inf)`. Locally, you can test your hill-climbing implementation using the functions you defined in Task 2.3.\n",
    "\n",
    "If you are certain that your solution is correct but the test cases fail, just rerun your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_climbing(\n",
    "    cities: int,\n",
    "    distances: List[Tuple[int]],\n",
    "    transition: Callable,\n",
    "    evaluation_func: Callable\n",
    ") -> List[int]:\n",
    "    \"\"\"\n",
    "    Hill climbing finds the solution to reach the goal from the initial.\n",
    "\n",
    "    Args:\n",
    "        cities (int): The number of cities to be visited.\n",
    "\n",
    "        distances (List[Tuple[int]]): The list of distances between every two cities. Each distance\n",
    "            is represented as a tuple in the form of (c1, c2, d), where c1 and c2 are the two cities\n",
    "            and d is the distance between them. The length of the list should be equal to cities *\n",
    "            (cities - 1)/2.\n",
    "\n",
    "        transition (Callable): A function that generates new routes to be used in the next\n",
    "            iteration in the hill-climbing algorithm. Will be provided on Coursemology.\n",
    "\n",
    "        evaluation_func (Callable): A function that computes the evaluation score of a route. Will\n",
    "            be provided on Coursemology.\n",
    "\n",
    "    Returns:\n",
    "        route (List[int]): The shortest route, represented by a list of cities in the order to be\n",
    "            traversed.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "# Test cases\n",
    "def test_hill_climbing(cities: int, distances: List[Tuple[int]], transition: callable, evaluation_func: callable):\n",
    "    route = hill_climbing(cities, distances, transition, evaluation_func)\n",
    "    assert sorted(route) == list(range(cities)), \"New route does not contain all cities present in the original route.\"\n",
    "\n",
    "cities_1 = 4\n",
    "distances_1 = [(1, 0, 10), (0, 3, 22), (2, 1, 8), (2, 3, 30), (1, 3, 25), (0, 2, 15)]\n",
    "\n",
    "test_hill_climbing(cities_1, distances_1, transition, evaluation_func)\n",
    "\n",
    "cities_2 = 10\n",
    "distances_2 = [(2, 7, 60), (1, 6, 20), (5, 4, 70), (9, 8, 90), (3, 7, 54), (2, 5, 61),\n",
    "    (4, 1, 106), (0, 6, 51), (3, 1, 45), (0, 5, 86), (9, 2, 73), (8, 4, 14), (0, 1, 51),\n",
    "    (9, 7, 22), (3, 2, 22), (8, 1, 120), (5, 7, 92), (5, 6, 60), (6, 2, 10), (8, 3, 78),\n",
    "    (9, 6, 82), (0, 2, 41), (2, 8, 99), (7, 8, 71), (0, 9, 32), (4, 0, 73), (0, 3, 42),\n",
    "    (9, 1, 80), (4, 2, 85), (5, 9, 113), (3, 6, 28), (5, 8, 81), (3, 9, 72), (9, 4, 81),\n",
    "    (5, 3, 45), (7, 4, 60), (6, 8, 106), (0, 8, 85), (4, 6, 92), (7, 6, 70), (7, 0, 22),\n",
    "    (7, 1, 73), (4, 3, 64), (5, 1, 80), (2, 1, 22)]\n",
    "\n",
    "test_hill_climbing(cities_2, distances_2, transition, evaluation_func)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.7: Improve hill-climbing with random restarts\n",
    "\n",
    "When no \"better\" neighbouring solutions are present, local search can be stuck at a local maxima. One way to combat this is to simply repeat local search from random initial states, taking the best performing iteration. \n",
    "\n",
    "Implement `hill_climbing_with_random_restarts(cities, distances, tansition, evaluation_func, hill_climbing, repeats)` by repeating hill climbing at different random locations.\n",
    "\n",
    "* Coursemology will tests this question with correct implementation of `transition(route)`, `evaluation_func(cities, distances, route)` and `hill_climbing(cities, distances, transition, evaluation_func)`\n",
    "* Note that the implemented `evaluation_func(cities, distances, route)` returns a float, which can be from `float(-inf)` to `float(inf)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_climbing_with_random_restarts(\n",
    "    cities: int,\n",
    "    distances: List[Tuple[int]],\n",
    "    transition: Callable,\n",
    "    evaluation_func: Callable,\n",
    "    hill_climbing: Callable,\n",
    "    repeats: int = 10\n",
    ") -> List[int]:\n",
    "    \"\"\"\n",
    "    Hill climbing with random restarts finds the solution to reach the goal from the initial.\n",
    "\n",
    "    Args:\n",
    "        cities (int): The number of cities to be visited.\n",
    "\n",
    "        distances (List[Tuple[int]]): The list of distances between every two cities. Each distance\n",
    "            is represented as a tuple in the form of (c1, c2, d), where c1 and c2 are the two cities\n",
    "            and d is the distance between them. The length of the list should be equal to cities *\n",
    "            (cities - 1)/2.\n",
    "\n",
    "        transition (Callable): The transition function to be used in hill climbing. Will be\n",
    "            provided on Coursemology.\n",
    "\n",
    "        evaluation_func (Callable): The evaluation function to be used in hill climbing. Will be\n",
    "            provided on Coursemology.\n",
    "\n",
    "        hill_climbing (Callable): The hill climbing function to be used for each restart. Will be\n",
    "            provided on Coursemology.\n",
    "\n",
    "        repeats (int): The number of times hill climbing to be repeated. The default value is 10.\n",
    "\n",
    "    Returns:\n",
    "        route (List[int]): The shortest route, represented by a list of cities in the order to be\n",
    "            traversed.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "# Test cases\n",
    "def test_random_restarts(cities: int, distances: List[Tuple[int]], transition, evaluation_func, hill_climbing, hill_climbing_with_random_restarts, repeats: int = 10):\n",
    "    route = hill_climbing_with_random_restarts(cities, distances, transition, evaluation_func, hill_climbing, repeats)\n",
    "    assert sorted(route) == list(range(cities)), \"New route does not contain all cities present in the original route.\"\n",
    "\n",
    "cities_1 = 4\n",
    "distances_1 = [(1, 0, 10), (0, 3, 22), (2, 1, 8), (2, 3, 30), (1, 3, 25), (0, 2, 15)]\n",
    "\n",
    "test_random_restarts(cities_1, distances_1, transition, evaluation_func, hill_climbing, hill_climbing_with_random_restarts)\n",
    "\n",
    "cities_2 = 10\n",
    "distances_2 = [(2, 7, 60), (1, 6, 20), (5, 4, 70), (9, 8, 90), (3, 7, 54), (2, 5, 61),\n",
    "    (4, 1, 106), (0, 6, 51), (3, 1, 45), (0, 5, 86), (9, 2, 73), (8, 4, 14), (0, 1, 51),\n",
    "    (9, 7, 22), (3, 2, 22), (8, 1, 120), (5, 7, 92), (5, 6, 60), (6, 2, 10), (8, 3, 78),\n",
    "    (9, 6, 82), (0, 2, 41), (2, 8, 99), (7, 8, 71), (0, 9, 32), (4, 0, 73), (0, 3, 42),\n",
    "    (9, 1, 80), (4, 2, 85), (5, 9, 113), (3, 6, 28), (5, 8, 81), (3, 9, 72), (9, 4, 81),\n",
    "    (5, 3, 45), (7, 4, 60), (6, 8, 106), (0, 8, 85), (4, 6, 92), (7, 6, 70), (7, 0, 22),\n",
    "    (7, 1, 73), (4, 3, 64), (5, 1, 80), (2, 1, 22)]\n",
    "\n",
    "test_random_restarts(cities_2, distances_2, transition, evaluation_func, hill_climbing, hill_climbing_with_random_restarts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.8: Comparison between local search and other search algorithms\n",
    "\n",
    "Compared to previous search algorithms you have seen (uninformed search, A* search), why do you think local search is more suitable for this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakthrough\n",
    "\n",
    "Breakthrough was the winner of the 2001 8 × 8 Game Design Competition, sponsored by *About.com* and *Abstract Games Magazine*. When Dan Troyka formulated it, it was originally for a 7×7 board. We’re going to play it on a 6×6 board to limit the complexity. In terms of our terminology for the agent environment, Breakthrough is a fully observable, strategic, deterministic game. The game always results in a win for one of the two players.\n",
    "\n",
    "How exactly do you design an agent to play this game and, most importantly, win? An agent takes sensory input and reasons about it, and then outputs an action at each time step. You thus need to create a program that can read in a representation of the board (that’s the input) and output a legal move in Breakthrough. You then need an evaluation function to evaluate how good a position is.\n",
    "\n",
    "In this problem set, you will first implement a minimax agent, followed by augmenting it with alpha-beta pruning. You will then implement an improved evaluation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakthrough Technical Description\n",
    "\n",
    "<pre>\n",
    "<p style=\"text-align: center;\">\n",
    "<img src=\"images/breakthrough_board.png\">\n",
    "Figure 1. Game Board\n",
    "</p>\n",
    "</pre>\n",
    "\n",
    "*Figure 1* shows the starting position of our game board. The player controlling the black pieces can move the black pawns (**B**), and the other player controlling the white pieces can move the white pawns (**W**). Each player can only move pieces of their own colour during their turn. Black can move its pawns forward towards the bottom of the board, while white can move its pawns forward towards the top of the board. Black wins by moving any piece to the opposite side, row (horizontal) index 5. White wins by moving any piece to row (horizontal) index 0. A side also wins if their opponent has no pieces left. **Kindly follow the same indexing as provided in *Figure 1***.\n",
    "\n",
    "<pre>\n",
    "<p style=\"text-align: center;\">\n",
    "<img src=\"images/game_move_black.png\">\n",
    "Figure 2. Possible Moves for Black\n",
    "</p>\n",
    "</pre>\n",
    "\n",
    "Pieces move one space directly forward or diagonally forward, and only capture diagonally forward. An example of possible moves for black is illustrated in *Figure 2*. In this figure, the black pawn at (3, 2) can move forward to any of the three spaces in row index 4. The black pawn at (0, 4) can either move diagonally right to (1, 5), or capture by moving diagonally left to (1, 3). It cannot capture by moving forward; its forward movement is blocked by the white pawn at (1, 4). Note that your move is not allowed to take your pawn outside the board.\n",
    "\n",
    "<pre>\n",
    "<p style=\"text-align: center;\">\n",
    "<img src=\"images/game_move_white.png\">\n",
    "Figure 3. Possible Moves for White\n",
    "</p>\n",
    "</pre>\n",
    "\n",
    "The same movement rules apply to white as illustrated in *Figure 3*. In this figure, the white pawn at (1, 3) can move forward to any of the three spaces in row index 0. The white pawn at (4, 2) can either move diagonally right to (3, 3), or capture by moving diagonally left to (3, 1). It cannot capture by moving forward; its forward movement is blocked by the black pawn at (3, 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided Utility Functions\n",
    "\n",
    "You can use the functions provided in *breakthrough.py* file as you see fit. These functions have mainly been used by the game playing framework to facilitate the two player game. A short description of these functions is given below:\n",
    "\n",
    "- `Player.get_opponent()`: Given a player colour, it returns the opponent's colour.\n",
    "- `print_state(board)`: It takes in the board 2D list as parameter and prints out the current state of the board in a comprehensible way.\n",
    "- `is_valid_move(board, src, dst, current_player)`: It takes in the board configuration, move source, move destination and current player colour as its parameters. It returns `True` if the move is valid and returns `False` if the move is invalid.\n",
    "- `make_move(curr_board, src, dst, current_player, in_place=True)`: Given a board configuration, move source and move destination and current player colour, this function updates the board configuration based on the indicated move. This function updates the board configuration by modifying existing values if `in_place` is set to `True`, or creating a new board with updated values if `in_place` is set to `False`.\n",
    "- `is_game_over(board)`: Given a board configuration, it returns `True` if the game is over, `False` otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the following cell before proceeding. You may use any of the imported libraries/classes here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run this cell before you start!\n",
    "\"\"\"\n",
    "\n",
    "import copy\n",
    "from typing import Callable, Union\n",
    "\n",
    "import breakthrough\n",
    "\n",
    "Score = Union[int, float]\n",
    "Move = tuple[tuple[int, int], tuple[int, int]]\n",
    "Board = list[list[str]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build your own agent, you will need a heuristic function to evaluate a position. The heuristic function below evaluates the board from black's perspective. You will be using this heuristic function for tasks 3 and 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(board: Board) -> Score:\n",
    "    \"\"\"\n",
    "    Returns the score of the current position.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    board: 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "    representing black pawn, white pawn, and empty cell, respectively.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    An evaluation (as a Score).\n",
    "    \"\"\"\n",
    "    bcount = 0\n",
    "    wcount = 0\n",
    "    for r, row in enumerate(board):\n",
    "        for tile in row:\n",
    "            if tile == \"B\":\n",
    "                if r == 5:\n",
    "                    return breakthrough.WIN\n",
    "                bcount += 1\n",
    "            elif tile == \"W\":\n",
    "                if r == 0:\n",
    "                    return -breakthrough.WIN\n",
    "                wcount += 1\n",
    "    if wcount == 0:\n",
    "        return breakthrough.WIN\n",
    "    if bcount == 0:\n",
    "        return -breakthrough.WIN\n",
    "    return bcount - wcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided heuristic function returns `breakthrough.WIN` if black wins, and `-breakthrough.WIN` if white wins. Otherwise, it takes the difference between the number of black pieces and the number of white pieces that are on the board. The value of `breakthrough.WIN` can be found in `breakthrough.py` and has a value of `21092109`.\n",
    "\n",
    "**Note**: On Coursemology, we will provide and use this heuristic function to test your code in task 3 and task 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Implement a function to generate all valid moves\n",
    "\n",
    "It is useful to generate all the possible moves that the current player can make in a certain position. You may need this function when implementing the minimax algorithm.\n",
    "\n",
    "Implement `generate_valid_moves(board, current_player)` to generate all possible moves for a player given the current board state. The function should work for the current player to move, whether it is black or white.\n",
    "\n",
    "**Note**: On Coursemology, we will provide you with the correct implementation of `generate_valid_moves` in task 3 and task 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_valid_moves(\n",
    "    board: Board,\n",
    "    current_player: breakthrough.Player\n",
    ") -> list[Move]:\n",
    "    \"\"\"\n",
    "    Generates a list containing all possible moves in a particular position for the current player\n",
    "    to move. Return an empty list if there are no possible moves.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    board: 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "        representing black pawn, white pawn, and empty cell, respectively.\n",
    "\n",
    "    current_player: breakthrough.Player, the colour of the current player to move.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list of Moves.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "# Test cases\n",
    "board_21 = [\n",
    "    list(\"__B___\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"_W____\"),\n",
    "]\n",
    "\n",
    "board_22 = [\n",
    "    list(\"____B_\"),\n",
    "    list(\"_____B\"),\n",
    "    list(\"_W____\"),\n",
    "    list(\"__W___\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "board_23 = [\n",
    "    list(\"______\"),\n",
    "    list(\"__B___\"),\n",
    "    list(\"_WWW__\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "assert sorted(generate_valid_moves(board_21, breakthrough.Player.BLACK)) == [((0, 2), (1, 1)), ((0, 2), (1, 2)), ((0, 2), (1, 3))], \"Moves generated for black on board_21 is incorrect\"\n",
    "assert sorted(generate_valid_moves(board_21, breakthrough.Player.WHITE)) == [((5, 1), (4, 0)), ((5, 1), (4, 1)), ((5, 1), (4, 2))], \"Moves generated for white on board_21 is incorrect\"\n",
    "assert sorted(generate_valid_moves(board_22, breakthrough.Player.BLACK)) == [((0, 4), (1, 3)), ((0, 4), (1, 4)), ((1, 5), (2, 4)), ((1, 5), (2, 5))], \"Moves generated for black on board_22 is incorrect\"\n",
    "assert sorted(generate_valid_moves(board_22, breakthrough.Player.WHITE)) == [((2, 1), (1, 0)), ((2, 1), (1, 1)), ((2, 1), (1, 2)), ((3, 2), (2, 2)), ((3, 2), (2, 3))], \"Moves generated for white on board_22 is incorrect\"\n",
    "assert sorted(generate_valid_moves(board_23, breakthrough.Player.BLACK)) == [((1, 2), (2, 1)), ((1, 2), (2, 3))], \"Moves generated for black on board_23 is incorrect\"\n",
    "assert sorted(generate_valid_moves(board_23, breakthrough.Player.WHITE)) == [((2, 1), (1, 0)), ((2, 1), (1, 1)), ((2, 1), (1, 2)), ((2, 2), (1, 1)), ((2, 2), (1, 3)), ((2, 3), (1, 2)), ((2, 3), (1, 3)), ((2, 3), (1, 4))], \"Moves generated for white on board_23 is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax Algorithm\n",
    "\n",
    "Your agent must be able to calculate the game state a few moves in advance, by implementing the **minimax** algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1: Implement minimax\n",
    "\n",
    "In the lecture, you have seen the minimax algorithm without and with cutoff. We will implement a minimax algorithm with cutoff in this case, as the depth of the game and the branching factor in certain positions can be (very) large and we do not have the computational power to compute the entire game until the terminal states.\n",
    "\n",
    "Your minimax function should explore different game states, until either the depth is `max_depth`, or there is a winner. In these cases, your minimax algorithm should use the provided heuristic function, `evaluate(board)` to evaluate the position.\n",
    "\n",
    "Your minimax function must be able to handle making the first move for either black or white. Regardless of which player moves first, the minimax evaluation should always be done from the perspective of black.\n",
    "\n",
    "**Note**: For tasks 3.1 to 4.2, if you are certain that your solution is correct but the test cases fail on Coursemology due to timeout, just rerun your code. Depending on the load on Coursemology, a correct solution might still timeout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax(\n",
    "    board: Board,\n",
    "    depth: int,\n",
    "    max_depth: int,\n",
    "    current_player: breakthrough.Player,\n",
    "    generate_valid_moves: Callable\n",
    ") -> tuple[Score, Move]:\n",
    "    \"\"\"\n",
    "    Finds the best move for the current player and corresponding evaluation from black's\n",
    "    perspective for the input board state. Return breakthrough.MOVE_NONE if no move is possible\n",
    "    (e.g. when the game is over).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    board: 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "        representing black pawn, white pawn, and empty cell, respectively. Your function may modify\n",
    "        the board internally, but the original board passed as an argument must remain unchanged.\n",
    "\n",
    "    depth: int, the depth to search for the best move. When this is equal to `max_depth`, you\n",
    "        should get the evaluation of the position using the provided heuristic function.\n",
    "\n",
    "    max_depth: int, the maximum depth for cutoff.\n",
    "\n",
    "    current_player: breakthrough.Player, the colour of the current player to move.\n",
    "\n",
    "    generate_valid_moves: Callable, move generation function. Will be provided on Coursemology.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A tuple (evaluation, ((src_row, src_col), (dst_row, dst_col))):\n",
    "    evaluation: the best score that the current player to move can achieve.\n",
    "    src_row, src_col: position of the pawn to move.\n",
    "    dst_row, dst_col: position to move the pawn to.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preservation_board = [\n",
    "    list(\"___B__\"),\n",
    "    list(\"______\"),\n",
    "    list(\"_B__B_\"),\n",
    "    list(\"W____W\"),\n",
    "    list(\"___W__\"),\n",
    "    list(\"_W____\"),\n",
    "]\n",
    "\n",
    "game_over_board_1 = [\n",
    "    list(\"______\"),\n",
    "    list(\"_W____\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "game_over_board_2 = [\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"_B____\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "max_depth_board_1 = [\n",
    "    list(\"______\"),\n",
    "    list(\"W_____\"),\n",
    "    list(\"______\"),\n",
    "    list(\"_____B\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "max_depth_board_2 = [\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"W_____\"),\n",
    "    list(\"______\"),\n",
    "    list(\"_____B\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "player_switching_board = [\n",
    "    list(\"___B__\"),\n",
    "    list(\"______\"),\n",
    "    list(\"_B__B_\"),\n",
    "    list(\"W____W\"),\n",
    "    list(\"______\"),\n",
    "    list(\"___W__\"),\n",
    "]\n",
    "\n",
    "board_31 = [\n",
    "    list(\"______\"),\n",
    "    list(\"___B__\"),\n",
    "    list(\"____BB\"),\n",
    "    list(\"___WB_\"),\n",
    "    list(\"_B__WW\"),\n",
    "    list(\"_WW___\"),\n",
    "]\n",
    "\n",
    "board_32 = [\n",
    "    list(\"______\"),\n",
    "    list(\"_____B\"),\n",
    "    list(\"_W____\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "board_33 = [\n",
    "    list(\"______\"),\n",
    "    list(\"__B___\"),\n",
    "    list(\"W_____\"),\n",
    "    list(\"___B_B\"),\n",
    "    list(\"__W___\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "board_34 = [\n",
    "    list(\"______\"),\n",
    "    list(\"____BB\"),\n",
    "    list(\"__B____\"),\n",
    "    list(\"_W_B_B\"),\n",
    "    list(\"__W_W_\"),\n",
    "    list(\"___WW_\"),\n",
    "]\n",
    "\n",
    "def invoke_search_fn(search_fn, board, max_depth, current_player):\n",
    "    if \"alpha_beta\" in search_fn.__name__:\n",
    "        return search_fn(board, 0, max_depth, -breakthrough.INF, breakthrough.INF, current_player, generate_valid_moves)\n",
    "    else:\n",
    "        return search_fn(board, 0, max_depth, current_player, generate_valid_moves)\n",
    "\n",
    "def test_board_preservation(search_fn):\n",
    "    control_board = copy.deepcopy(preservation_board)\n",
    "    input_board = copy.deepcopy(preservation_board)\n",
    "    invoke_search_fn(search_fn, input_board, 2, breakthrough.Player.BLACK)\n",
    "    assert control_board == input_board, \"Your function may be modifying the board by making moves in place.\"\n",
    "\n",
    "def test_game_over(search_fn, board, expected_score):\n",
    "    score, move = invoke_search_fn(search_fn, board, 1, breakthrough.Player.BLACK)\n",
    "    assert score == expected_score, \"Your function might not have terminated when the game is over.\"\n",
    "    assert move == breakthrough.MOVE_NONE, \"Your function might not be returning breakthrough.MOVE_NONE when no moves are possible or it might be generating moves for the opponent instead.\"\n",
    "\n",
    "def test_max_depth(search_fn, board, current_player, expected_moves):\n",
    "    score, move = invoke_search_fn(search_fn, board, 1, current_player)\n",
    "    assert score == 0, f\"Your function may not be terminating at max depth or you may be initialising {current_player.value}'s score incorrectly.\"\n",
    "    assert move in expected_moves, f\"Your function does not move {current_player.value} pieces during {current_player.value}'s turn, or initialises {current_player.value}'s score incorrectly or terminates early.\"\n",
    "\n",
    "def test_player_switching(search_fn, current_player):\n",
    "    score, _ = invoke_search_fn(search_fn, player_switching_board, 2, current_player)\n",
    "    assert score != 2, \"Your function may not be switching player's colours correctly after making a move.\"\n",
    "    assert score == 0, \"Your function may not be making the most optimal move at each depth.\"\n",
    "\n",
    "def test_search(search_fn, board, max_depth, current_player, expected_score, expected_moves):\n",
    "    score, move = invoke_search_fn(search_fn, board, max_depth, current_player)\n",
    "    assert score == expected_score, f\"Final evaluation score should be {expected_score} instead of {score}.\"\n",
    "    assert move in expected_moves, f\"Your function does not correctly move {current_player.value}'s pieces despite having the correct evaluation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "test_board_preservation(minimax)\n",
    "test_game_over(minimax, game_over_board_1, -breakthrough.WIN)\n",
    "test_game_over(minimax, game_over_board_2, breakthrough.WIN)\n",
    "test_max_depth(minimax, max_depth_board_1, breakthrough.Player.BLACK, [((3, 5), (4, 4)), ((3, 5), (4, 5))])\n",
    "test_max_depth(minimax, max_depth_board_2, breakthrough.Player.WHITE, [((2, 0), (1, 0)), ((2, 0), (1, 1))])\n",
    "test_player_switching(minimax, breakthrough.Player.BLACK)\n",
    "test_player_switching(minimax, breakthrough.Player.WHITE)\n",
    "\n",
    "test_search(minimax, board_31, 1, breakthrough.Player.BLACK, breakthrough.WIN, [((4, 1), (5, 0)), ((4, 1), (5, 2))])\n",
    "test_search(minimax, board_32, 4, breakthrough.Player.BLACK, -breakthrough.WIN, [((1, 5), (2, 5)), ((1, 5), (2, 4))])\n",
    "test_search(minimax, board_33, 3, breakthrough.Player.WHITE, -breakthrough.WIN, [((2, 0), (1, 0)), ((2, 0), (1, 1))])\n",
    "test_search(minimax, board_34, 3, breakthrough.Player.WHITE, -1, [((3, 1), (2, 2)), ((4, 2), (3, 3)), ((4, 4), (3, 3)), ((4, 4), (3, 5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Implement negamax\n",
    "\n",
    "You may notice that Breakthrough is a zero-sum game. It means that the sum of the evaluation scores of the two players should be zero.\n",
    "\n",
    "For example, we can consider a position in which there are _9 black pawns_ and _6 white pawns_. Using the sample heuristic function given at the start:\n",
    "\n",
    "- The evaluation score of black in this position is `+3`.\n",
    "- The evaluation score of white in this position is `-3`.\n",
    "\n",
    "Using this property, we can simplify the implementation of minimax. Instead of taking the maximum and minimum scores for black and white respectively, we can negate the score of the opposite player and take the maximum score. This version is called **negamax**. Your negamax function must be able to handle making the first move for either black or white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negamax(\n",
    "    board: Board,\n",
    "    depth: int,\n",
    "    max_depth: int,\n",
    "    current_player: breakthrough.Player,\n",
    "    generate_valid_moves: Callable\n",
    ") -> tuple[Score, Move]:\n",
    "    \"\"\"\n",
    "    Finds the best move for the current player and corresponding evaluation for the input board\n",
    "    state. Return breakthrough.MOVE_NONE if no move is possible (e.g. when the game is over).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    board: 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "        representing black pawn, white pawn, and empty cell, respectively. Your function may modify\n",
    "        the board internally, but the original board passed as an argument must remain unchanged.\n",
    "\n",
    "    depth: int, the depth to search for the best move. When this is equal to `max_depth`, you\n",
    "        should get the evaluation of the position using the provided heuristic function.\n",
    "\n",
    "    max_depth: int, the maximum depth for cutoff.\n",
    "\n",
    "    current_player: breakthrough.Player, the colour of the current player to move.\n",
    "\n",
    "    generate_valid_moves: Callable, move generation function. Will be provided on Coursemology.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A tuple (evaluation, ((src_row, src_col), (dst_row, dst_col))):\n",
    "    evaluation: the best score that the current player to move can achieve.\n",
    "    src_row, src_col: position of the pawn to move.\n",
    "    dst_row, dst_col: position to move the pawn to.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "test_board_preservation(negamax)\n",
    "test_game_over(negamax, game_over_board_1, -breakthrough.WIN)\n",
    "test_game_over(negamax, game_over_board_2, breakthrough.WIN)\n",
    "test_max_depth(negamax, max_depth_board_1, breakthrough.Player.BLACK, [((3, 5), (4, 4)), ((3, 5), (4, 5))])\n",
    "test_max_depth(negamax, max_depth_board_2, breakthrough.Player.WHITE, [((2, 0), (1, 0)), ((2, 0), (1, 1))])\n",
    "test_player_switching(negamax, breakthrough.Player.BLACK)\n",
    "test_player_switching(negamax, breakthrough.Player.WHITE)\n",
    "\n",
    "test_search(negamax, board_31, 1, breakthrough.Player.BLACK, breakthrough.WIN, [((4, 1), (5, 0)), ((4, 1), (5, 2))])\n",
    "test_search(negamax, board_32, 4, breakthrough.Player.BLACK, -breakthrough.WIN, [((1, 5), (2, 5)), ((1, 5), (2, 4))])\n",
    "test_search(negamax, board_33, 3, breakthrough.Player.WHITE, -breakthrough.WIN, [((2, 0), (1, 0)), ((2, 0), (1, 1))])\n",
    "test_search(negamax, board_34, 3, breakthrough.Player.WHITE, -1, [((3, 1), (2, 2)), ((4, 2), (3, 3)), ((4, 4), (3, 3)), ((4, 4), (3, 5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha-beta Pruning\n",
    "\n",
    "With minimax (or negamax), our agent can see the future within a few moves. However, the naive implementation of minimax (or negamax) may explore many redundant states, which slows down our agent. As discussed in the lecture, we can apply **alpha-beta pruning** to eliminate unnecessary states, thereby improving our agent's speed and its ability to see even further into the future. This will increase our agent's strength and its likelihood of winning the game. \n",
    "\n",
    "First, you should try to integrate alpha-beta pruning with the standard minimax algorithm. Similar to Task 3.1, your minimax function with alpha-beta pruning must be able to handle making the first move for either black or white."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1: Integrate alpha-beta pruning into minimax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax_alpha_beta(\n",
    "    board: Board,\n",
    "    depth: int,\n",
    "    max_depth: int,\n",
    "    alpha: Score,\n",
    "    beta: Score,\n",
    "    current_player: breakthrough.Player,\n",
    "    generate_valid_moves: Callable\n",
    ") -> tuple[Score, Move]:\n",
    "    \"\"\"\n",
    "    Finds the best move for the current player and corresponding evaluation from black's\n",
    "    perspective for the input board state. Return breakthrough.MOVE_NONE if no move is possible\n",
    "    (e.g. when the game is over).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    board: 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "        representing black pawn, white pawn, and empty cell, respectively. Your function may modify\n",
    "        the board internally, but the original board passed as an argument must remain unchanged.\n",
    "\n",
    "    depth: int, the depth to search for the best move. When this is equal to `max_depth`, you\n",
    "        should get the evaluation of the position using the provided heuristic function.\n",
    "\n",
    "    max_depth: int, the maximum depth for cutoff.\n",
    "\n",
    "    alpha: Score. The alpha value in a given state.\n",
    "\n",
    "    beta: Score. The beta value in a given state.\n",
    "\n",
    "    current_player: breakthrough.Player, the colour of the current player\n",
    "        to move.\n",
    "\n",
    "    generate_valid_moves: Callable, move generation function. Will be\n",
    "        provided on Coursemology.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A tuple (evaluation, ((src_row, src_col), (dst_row, dst_col))):\n",
    "    evaluation: the best score that the current player to move can achieve.\n",
    "    src_row, src_col: position of the pawn to move.\n",
    "    dst_row, dst_col: position to move the pawn to.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_41 = [\n",
    "    list(\"______\"),\n",
    "    list(\"__BB__\"),\n",
    "    list(\"____BB\"),\n",
    "    list(\"WBW_B_\"),\n",
    "    list(\"____WW\"),\n",
    "    list(\"_WW___\"),\n",
    "]\n",
    "\n",
    "board_42 = [\n",
    "    list(\"____B_\"),\n",
    "    list(\"__BB__\"),\n",
    "    list(\"______\"),\n",
    "    list(\"_WWW__\"),\n",
    "    list(\"____W_\"),\n",
    "    list(\"______\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "test_board_preservation(minimax_alpha_beta)\n",
    "test_game_over(minimax_alpha_beta, game_over_board_1, -breakthrough.WIN)\n",
    "test_game_over(minimax_alpha_beta, game_over_board_2, breakthrough.WIN)\n",
    "test_max_depth(minimax_alpha_beta, max_depth_board_1, breakthrough.Player.BLACK, [((3, 5), (4, 4)), ((3, 5), (4, 5))])\n",
    "test_max_depth(minimax_alpha_beta, max_depth_board_2, breakthrough.Player.WHITE, [((2, 0), (1, 0)), ((2, 0), (1, 1))])\n",
    "test_player_switching(minimax_alpha_beta, breakthrough.Player.BLACK)\n",
    "test_player_switching(minimax_alpha_beta, breakthrough.Player.WHITE)\n",
    "\n",
    "test_search(minimax_alpha_beta, board_41, 3, breakthrough.Player.BLACK, breakthrough.WIN, [((3, 4), (4, 5))])\n",
    "test_search(minimax_alpha_beta, board_42, 6, breakthrough.Player.BLACK, -breakthrough.WIN, [((0, 4), (1, 4)), ((0, 4), (1, 5)), ((1, 2), (2, 2)), ((1, 2), (2, 1)), ((1, 2), (2, 3)), ((1, 3), (2, 3)), ((1, 3), (2, 2)), ((1, 3), (2, 4))])\n",
    "test_search(minimax_alpha_beta, board_33, 3, breakthrough.Player.WHITE, -breakthrough.WIN, [((2, 0), (1, 0)), ((2, 0), (1, 1))])\n",
    "test_search(minimax_alpha_beta, board_34, 3, breakthrough.Player.WHITE, -1, [((3, 1), (2, 2)), ((4, 2), (3, 3)), ((4, 4), (3, 3)), ((4, 4), (3, 5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2: Integrate alpha-beta pruning into negamax\n",
    "\n",
    "At this stage, you may wonder: why don't we integrate alpha-beta pruning with the alternative, negamax? Of course, we can also incorporate alpha-beta pruning into our negamax algorithm to improve its performance.\n",
    "\n",
    "Remember, we exploited the zero-sum property of the game to implement negamax by negating the evaluation score, and always taking the maximum score instead of alternating between the maximum and minimum. You need to further exploit this property to correctly integrate alpha-beta pruning into negamax. To help you, these are some questions that you can try to answer:\n",
    "\n",
    "- What is the meaning of `alpha` and `beta`?\n",
    "- From the perspective of the opponent, what is the corresponding `alpha` and `beta`? Can I exploit the zero-sum property here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negamax_alpha_beta(\n",
    "    board: Board,\n",
    "    depth: int,\n",
    "    max_depth: int,\n",
    "    alpha: Score,\n",
    "    beta: Score,\n",
    "    current_player: breakthrough.Player,\n",
    "    generate_valid_moves: Callable\n",
    ") -> tuple[Score, Move]:\n",
    "    \"\"\"\n",
    "    Finds the best move for the current player and corresponding evaluation for the input board\n",
    "    state. Return breakthrough.MOVE_NONE if no move is possible (e.g. when the game is over).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    board: 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "        representing black pawn, white pawn, and empty cell, respectively. Your function may modify\n",
    "        the board internally, but the original board passed as an argument must remain unchanged.\n",
    "\n",
    "    depth: int, the depth to search for the best move. When this is equal to `max_depth`, you\n",
    "        should get the evaluation of the position using the provided heuristic function.\n",
    "\n",
    "    max_depth: int, the maximum depth for cutoff.\n",
    "\n",
    "    alpha: Score. The alpha value in a given state.\n",
    "\n",
    "    beta: Score. The beta value in a given state.\n",
    "\n",
    "    current_player: breakthrough.Player, the colour of the current player to move.\n",
    "\n",
    "    generate_valid_moves: Callable, move generation function. Will be provided on Coursemology.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A tuple (evaluation, ((src_row, src_col), (dst_row, dst_col))):\n",
    "    evaluation: the best score that the current player to move can achieve.\n",
    "    src_row, src_col: position of the pawn to move.\n",
    "    dst_row, dst_col: position to move the pawn to.\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "test_board_preservation(negamax_alpha_beta)\n",
    "test_game_over(negamax_alpha_beta, game_over_board_1, -breakthrough.WIN)\n",
    "test_game_over(negamax_alpha_beta, game_over_board_2, breakthrough.WIN)\n",
    "test_max_depth(negamax_alpha_beta, max_depth_board_1, breakthrough.Player.BLACK, [((3, 5), (4, 4)), ((3, 5), (4, 5))])\n",
    "test_max_depth(negamax_alpha_beta, max_depth_board_2, breakthrough.Player.WHITE, [((2, 0), (1, 0)), ((2, 0), (1, 1))])\n",
    "test_player_switching(negamax_alpha_beta, breakthrough.Player.BLACK)\n",
    "test_player_switching(negamax_alpha_beta, breakthrough.Player.WHITE)\n",
    "\n",
    "test_search(negamax_alpha_beta, board_41, 3, breakthrough.Player.BLACK, breakthrough.WIN, [((3, 4), (4, 5))])\n",
    "test_search(negamax_alpha_beta, board_42, 6, breakthrough.Player.BLACK, -breakthrough.WIN, [((0, 4), (1, 4)), ((0, 4), (1, 5)), ((1, 2), (2, 2)), ((1, 2), (2, 1)), ((1, 2), (2, 3)), ((1, 3), (2, 3)), ((1, 3), (2, 2)), ((1, 3), (2, 4))])\n",
    "test_search(negamax_alpha_beta, board_33, 3, breakthrough.Player.WHITE, -breakthrough.WIN, [((2, 0), (1, 0)), ((2, 0), (1, 1))])\n",
    "test_search(negamax_alpha_beta, board_34, 3, breakthrough.Player.WHITE, -1, [((3, 1), (2, 2)), ((4, 2), (3, 3)), ((4, 4), (3, 3)), ((4, 4), (3, 5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic Function\n",
    "\n",
    "Phew, we finish the search algorithm! But, our heuristic function is too simple - it may not give the best evaluation for a position and we need a better one. Therefore, you shall implement the improved heuristic function described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.1: Implement an improved heuristic function\n",
    "\n",
    "Recall that the heuristic function should return a larger value when black is closer to winning. If black is closer to winning, black should have more pieces closer to row 5 compared to white having pieces closer to row 0. Of course this is not necessarily the case since you only need one piece to make it through while the rest remain behind, but this is just a heuristic after all. Thus, in this heuristic you are about to implement, we add more points if a black piece is closer to the end, and subtract more points if a white piece is closer to the end. The exact amount of points is shown in the figures below.\n",
    "\n",
    "<pre>\n",
    "<p style=\"text-align: center;\">\n",
    "<img src=\"images/black_heuristic.png\", width = 300>\n",
    "Figure 4. Points to add for each black piece in the square\n",
    "<p style=\"text-align: center;\">\n",
    "<img src=\"images/white_heuristic.png\", width = 300>\n",
    "Figure 5. Points to subtract for each white piece in the square\n",
    "</p>\n",
    "</pre>\n",
    "\n",
    "For example, if there are two black pieces on (0, 4) and (3, 2), and a white piece on (1, 4), then the output of the heuristic function should be `10 + 40 - 50 = 0`. Additionally, return `breakthrough.WIN` if any of black's pieces reach the end, and `-breakthrough.WIN` if any of white's pieces reach the end. Similarly, if white has no pieces, return `breakthrough.WIN`, and if black has no pieces, return `-breakthrough.WIN`. The value of `breakthrough.WIN` can be found in `breakthrough.py` and has a value of `21092109`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_evaluate(board: Board) -> Score:\n",
    "    \"\"\"\n",
    "    Returns the score of the current position with an improved heuristic.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    board: 2D list of lists. Contains characters \"B\", \"W\", and \"_\",\n",
    "        representing black pawn, white pawn, and empty cell, respectively.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    An improved evaluation (as a Score).\n",
    "    \"\"\"\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \"\"\" YOUR CODE END HERE \"\"\"\n",
    "\n",
    "# Test cases\n",
    "board_51 = [\n",
    "    list(\"___B__\"),\n",
    "    list(\"___W__\"),\n",
    "    list(\"______\"),\n",
    "    list(\"__B___\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "board_52 = [\n",
    "    list(\"___BW_\"),\n",
    "    list(\"___W__\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "board_53 = [\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "    list(\"__B___\"),\n",
    "    list(\"______\"),\n",
    "    list(\"______\"),\n",
    "]\n",
    "\n",
    "assert improved_evaluate(board_51) == 0, \"Your improved evaluation function should return 0 for this board.\"\n",
    "assert improved_evaluate(board_52) == -breakthrough.WIN, \"Your improved evaluation function does not correctly evaluate won positions.\"\n",
    "assert improved_evaluate(board_53) == breakthrough.WIN, \"Your improved evaluation function does not correctly evaluate won positions.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "\n",
    "To assist with your implementation, we have provided some examples as test cases. These are not sufficient to ensure that your code works correctly, and we encourage you to write your own additional test cases to test and debug your code.\n",
    "\n",
    "Note that your answers may be slightly different from the answers provided since multiple valid solutions may exist. During grading, your code will be evaluated on hidden test cases on top of the ones we have provided to check the quality of your search functions and algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
